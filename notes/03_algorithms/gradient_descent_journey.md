# Ph√¢n T√≠ch Th·ª±c Nghi·ªám To√†n Di·ªán v·ªÅ Gradient Descent: ƒê√°nh Gi√° Hi·ªáu Su·∫•t v√† So S√°nh Thu·∫≠t To√°n

## T√≥m T·∫Øt

Nghi√™n c·ª©u n√†y tr√¨nh b√†y m·ªôt ƒë√°nh gi√° th·ª±c nghi·ªám nghi√™m ng·∫∑t v·ªÅ c√°c thu·∫≠t to√°n t·ªëi ∆∞u gradient descent ƒë∆∞·ª£c √°p d·ª•ng cho c√°c b√†i to√°n h·ªìi quy quy m√¥ l·ªõn. Ch√∫ng t√¥i ƒëi·ªÅu tra m·ªôt c√°ch c√≥ h·ªá th·ªëng 21 c·∫•u h√¨nh t·ªëi ∆∞u kh√°c bi·ªát tr√™n c√°c ph∆∞∆°ng ph√°p gradient descent batch, ph√¢n t√≠ch t√≠nh ch·∫•t h·ªôi t·ª•, hi·ªáu qu·∫£ t√≠nh to√°n v√† kh·∫£ nƒÉng √°p d·ª•ng th·ª±c t·∫ø c·ªßa ch√∫ng. Khung th·ª±c nghi·ªám c·ªßa ch√∫ng t√¥i bao g·ªìm gradient descent truy·ªÅn th·ªëng v·ªõi c√°c chi·∫øn l∆∞·ª£c learning rate kh√°c nhau, k·ªπ thu·∫≠t ch√≠nh quy h√≥a (Ridge, Lasso), ph∆∞∆°ng ph√°p momentum ti√™n ti·∫øn (Nesterov acceleration), l·ªãch tr√¨nh learning rate th√≠ch ·ª©ng v√† quy tr√¨nh line search. ƒê√°nh gi√° ƒë∆∞·ª£c th·ª±c hi·ªán tr√™n m·ªôt b·ªô d·ªØ li·ªáu gi√° xe √¥ t√¥ ƒë√°ng k·ªÉ ch·ª©a 2.79 tri·ªáu m·∫´u v·ªõi 45 ƒë·∫∑c tr∆∞ng ƒë∆∞·ª£c thi·∫øt k·∫ø.

**Nh·ªØng Ph√°t Hi·ªán Ch√≠nh:** K·∫øt qu·∫£ c·ªßa ch√∫ng t√¥i ti·∫øt l·ªô s·ª± kh√°c bi·ªát ƒë√°ng k·ªÉ gi·ªØa c√°c ƒë·∫£m b·∫£o h·ªôi t·ª• l√Ω thuy·∫øt v√† hi·ªáu su·∫•t th·ª±c t·∫ø. Ch·ªâ c√≥ 9.5% s·ªë c·∫•u h√¨nh gradient descent ƒë∆∞·ª£c th·ª≠ nghi·ªám (2 trong s·ªë 21) ƒë·∫°t ƒë∆∞·ª£c h·ªôi t·ª• trong c√°c ti√™u ch√≠ dung sai ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh. Ch√≠nh quy h√≥a m·∫°nh xu·∫•t hi·ªán nh∆∞ y·∫øu t·ªë quan tr·ªçng cho ph√©p h·ªôi t·ª•, v·ªõi ch√≠nh quy h√≥a Ridge (Œª ‚â• 0.01) l√† c·∫ßn thi·∫øt cho s·ª± th√†nh c√¥ng c·ªßa thu·∫≠t to√°n.

**ƒê√≥ng G√≥p Nghi√™n C·ª©u:** C√¥ng tr√¨nh n√†y cung c·∫•p b·∫±ng ch·ª©ng th·ª±c nghi·ªám th√°ch th·ª©c c√°c th·ª±c h√†nh t·ªëi ∆∞u ti√™u chu·∫©n trong machine learning, ch·ª©ng minh t·∫ßm quan tr·ªçng then ch·ªët c·ªßa ƒëi·ªÅu ki·ªán b√†i to√°n trong vi·ªác l·ª±a ch·ªçn thu·∫≠t to√°n, v√† thi·∫øt l·∫≠p m·ªôt khung ƒë√°nh gi√° ph∆∞∆°ng ph√°p t·ªëi ∆∞u d·ª±a tr√™n d·ªØ li·ªáu trong c√°c t√¨nh hu·ªëng th·ª±c t·∫ø.

## 1. Gi·ªõi Thi·ªáu v√† M·ª•c Ti√™u Nghi√™n C·ª©u

C√°c ph∆∞∆°ng ph√°p t·ªëi ∆∞u d·ª±a tr√™n gradient t·∫°o n√™n n·ªÅn t·∫£ng t√≠nh to√°n c·ªßa machine learning hi·ªán ƒë·∫°i v√† suy lu·∫≠n th·ªëng k√™. Vi·ªác l·ª±a ch·ªçn c√°c thu·∫≠t to√°n t·ªëi ∆∞u ph√π h·ª£p ·∫£nh h∆∞·ªüng ƒë√°ng k·ªÉ ƒë·∫øn hi·ªáu qu·∫£ hu·∫•n luy·ªán m√¥ h√¨nh, ƒë·ªô tin c·∫≠y h·ªôi t·ª• v√† ch·∫•t l∆∞·ª£ng nghi·ªám cu·ªëi c√πng. M·∫∑c d√π t·ªìn t·∫°i vƒÉn hi·∫øn l√Ω thuy·∫øt phong ph√∫ v·ªÅ t√≠nh ch·∫•t h·ªôi t·ª• v√† gi·ªõi h·∫°n ƒë·ªô ph·ª©c t·∫°p, v·∫´n c√≤n m·ªôt kho·∫£ng c√°ch ƒë√°ng k·ªÉ gi·ªØa c√°c ƒë·∫£m b·∫£o l√Ω thuy·∫øt v√† hi·ªáu su·∫•t th·ª±c t·∫ø trong c√°c ·ª©ng d·ª•ng th·ª±c t·∫ø.

Nghi√™n c·ª©u n√†y gi·∫£i quy·∫øt ba c√¢u h·ªèi c∆° b·∫£n:

1. **T√≠nh B·ªÅn V·ªØng Thu·∫≠t To√°n**: C√°c bi·∫øn th·ªÉ gradient descent kh√°c nhau ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o khi ƒë∆∞·ª£c √°p d·ª•ng cho c√°c c·∫£nh quan t·ªëi ∆∞u ƒë·∫ßy th√°ch th·ª©c, th·ª±c t·∫ø?

2. **Kho·∫£ng C√°ch L√Ω Thuy·∫øt-Th·ª±c Ti·ªÖn**: C√°c ƒë·∫£m b·∫£o h·ªôi t·ª• l√Ω thuy·∫øt chuy·ªÉn ƒë·ªïi th√†nh c√¥ng thu·∫≠t to√°n th·ª±c t·∫ø ƒë·∫øn m·ª©c ƒë·ªô n√†o?

3. **L·ª±a Ch·ªçn Chi·∫øn L∆∞·ª£c T·ªëi ∆Øu**: Nh·ªØng ti√™u ch√≠ th·ª±c nghi·ªám n√†o n√™n h∆∞·ªõng d·∫´n vi·ªác l·ª±a ch·ªçn c√°c ph∆∞∆°ng ph√°p t·ªëi ∆∞u cho c√°c b√†i to√°n h·ªìi quy quy m√¥ l·ªõn?

ƒêi·ªÅu tra c·ªßa ch√∫ng t√¥i ƒë√°nh gi√° m·ªôt c√°ch c√≥ h·ªá th·ªëng 21 c·∫•u h√¨nh gradient descent, t·ª´ gradient descent c·ªï ƒëi·ªÉn v·ªõi learning rate c·ªë ƒë·ªãnh ƒë·∫øn c√°c ph∆∞∆°ng ph√°p th√≠ch ·ª©ng ph·ª©c t·∫°p v·ªõi momentum v√† ch√≠nh quy h√≥a. Thi·∫øt k·∫ø th·ª±c nghi·ªám nh·∫•n m·∫°nh t√≠nh t√°i t·∫°o, ƒë·ªô nghi√™m ng·∫∑t th·ªëng k√™ v√† √Ω nghƒ©a th·ª±c t·∫ø.

## 2. N·ªÅn T·∫£ng To√°n H·ªçc v√† Khung L√Ω Thuy·∫øt

### 2.1 C√¥ng Th·ª©c B√†i To√°n T·ªëi ∆Øu

Ch√∫ng t√¥i xem x√©t b√†i to√°n t·ªëi ∆∞u kh√¥ng r√†ng bu·ªôc t·ªïng qu√°t:

```
min f(x) = 1/2 ||Xw - y||¬≤ + R(w)
w ‚àà ‚Ñù·µà
```

trong ƒë√≥:

- `X ‚àà ‚Ñù‚ÅøÀ£·µà` bi·ªÉu di·ªÖn ma tr·∫≠n ƒë·∫∑c tr∆∞ng v·ªõi n m·∫´u v√† d ƒë·∫∑c tr∆∞ng
- `y ‚àà ‚Ñù‚Åø` k√Ω hi·ªáu vector m·ª•c ti√™u
- `w ‚àà ‚Ñù·µà` l√† c√°c tham s·ªë m√¥ h√¨nh c·∫ßn t·ªëi ∆∞u
- `R(w)` bi·ªÉu di·ªÖn s·ªë h·∫°ng ch√≠nh quy h√≥a

### 2.2 H·ªç Thu·∫≠t To√°n Gradient Descent

Quy t·∫Øc c·∫≠p nh·∫≠t gradient descent c∆° b·∫£n tu√¢n theo:

```
w‚Çñ‚Çä‚ÇÅ = w‚Çñ - Œ±‚Çñ‚àáf(w‚Çñ)
```

trong ƒë√≥:

- `w‚Çñ` k√Ω hi·ªáu vector tham s·ªë t·∫°i l·∫ßn l·∫∑p k
- `Œ±‚Çñ > 0` l√† learning rate (k√≠ch th∆∞·ªõc b∆∞·ªõc) t·∫°i l·∫ßn l·∫∑p k
- `‚àáf(w‚Çñ)` bi·ªÉu di·ªÖn gradient c·ªßa h√†m m·ª•c ti√™u t·∫°i w‚Çñ

### 2.3 L√Ω Thuy·∫øt H·ªôi T·ª•

**ƒê·ªãnh L√Ω 2.1 (H·ªôi T·ª• Tuy·∫øn T√≠nh)**: ƒê·ªëi v·ªõi c√°c h√†m l·ªìi m·∫°nh v·ªõi gradient Lipschitz li√™n t·ª•c, gradient descent v·ªõi k√≠ch th∆∞·ªõc b∆∞·ªõc ph√π h·ª£p ƒë·∫°t ƒë∆∞·ª£c h·ªôi t·ª• tuy·∫øn t√≠nh:

```
||w‚Çñ - w*||¬≤ ‚â§ œÅ·µè||w‚ÇÄ - w*||¬≤
```

trong ƒë√≥ œÅ = (Œ∫-1)/(Œ∫+1) < 1 v√† Œ∫ = L/Œº l√† s·ªë ƒëi·ªÅu ki·ªán.

**Ph√°c Th·∫£o Ch·ª©ng Minh**: T·ªëc ƒë·ªô h·ªôi t·ª• ph·ª• thu·ªôc c∆° b·∫£n v√†o s·ªë ƒëi·ªÅu ki·ªán Œ∫ = L/Œº, trong ƒë√≥ L l√† h·∫±ng s·ªë Lipschitz v√† Œº l√† tham s·ªë l·ªìi m·∫°nh.

### 2.4 T√°c ƒê·ªông Ch√≠nh Quy H√≥a ƒê·∫øn ƒêi·ªÅu Ki·ªán

Ch√≠nh quy h√≥a thay ƒë·ªïi c∆° b·∫£n c·∫£nh quan t·ªëi ∆∞u b·∫±ng c√°ch s·ª≠a ƒë·ªïi Hessian:

**Ch√≠nh Quy H√≥a Ridge**: `H_ridge = X·µÄX + ŒªI`
**Ch√≠nh Quy H√≥a Lasso**: Gi·ªõi thi·ªáu t√≠nh kh√¥ng tr∆°n y√™u c·∫ßu c√°c ph∆∞∆°ng ph√°p subgradient

Tham s·ªë ch√≠nh quy h√≥a Œª c·∫£i thi·ªán ƒëi·ªÅu ki·ªán b·∫±ng c√°ch ƒë·∫£m b·∫£o:

```
Œ∫_new = (Œª‚Çò‚Çê‚Çì + Œª)/(Œª‚Çò·µ¢‚Çô + Œª) < Œ∫_original = Œª‚Çò‚Çê‚Çì/Œª‚Çò·µ¢‚Çô
```

## 3. Ph∆∞∆°ng Ph√°p Th·ª±c Nghi·ªám v√† Thi·∫øt K·∫ø

### 3.1 ƒê·∫∑c T√≠nh T·∫≠p D·ªØ Li·ªáu

ƒê√°nh gi√° th·ª±c nghi·ªám c·ªßa ch√∫ng t√¥i s·ª≠ d·ª•ng m·ªôt b·ªô d·ªØ li·ªáu gi√° xe √¥ t√¥ to√†n di·ªán v·ªõi c√°c ƒë·∫∑c t·∫£ sau:

- **K√≠ch Th∆∞·ªõc M·∫´u**: 2,790,000 quan s√°t (2,230,000 hu·∫•n luy·ªán, 560,000 ki·ªÉm tra)
- **Chi·ªÅu ƒê·∫∑c Tr∆∞ng**: 45 ƒë·∫∑c tr∆∞ng ƒë∆∞·ª£c thi·∫øt k·∫ø t·ª´ 66 thu·ªôc t√≠nh g·ªëc
- **Bi·∫øn M·ª•c Ti√™u**: Gi√° xe ƒë∆∞·ª£c chuy·ªÉn ƒë·ªïi logarit ƒë·ªÉ gi·∫£i quy·∫øt ƒë·ªô l·ªách ph√¢n ph·ªëi
- **Ti·ªÅn X·ª≠ L√Ω**: ƒê·∫∑c tr∆∞ng ƒë∆∞·ª£c chu·∫©n h√≥a, m√£ h√≥a categorical, x·ª≠ l√Ω outlier

### 3.2 Kh√¥ng Gian C·∫•u H√¨nh Thu·∫≠t To√°n Gradient Descent

Ch√∫ng t√¥i ƒë√°nh gi√° m·ªôt c√°ch c√≥ h·ªá th·ªëng 21 c·∫•u h√¨nh t·ªëi ∆∞u gradient descent kh√°c bi·ªát:

#### 3.2.1 Gradient Descent C∆° B·∫£n (Setups 01-05)

1. **Setup 01**: Learning rate Œ± = 0.0001
2. **Setup 02**: Learning rate Œ± = 0.001
3. **Setup 03**: Learning rate Œ± = 0.01
4. **Setup 04**: Learning rate Œ± = 0.03
5. **Setup 05**: Learning rate Œ± = 0.2

#### 3.2.2 Ph∆∞∆°ng Ph√°p Ch√≠nh Quy H√≥a (Setups 06-08)

6. **Setup 06**: Ridge regression (Œª = 0.001, Œ± = 0.001)
7. **Setup 07**: Ridge regression (Œª = 0.001, Œ± = 0.1)
8. **Setup 08**: Ridge regression (Œª = 0.5, Œ± = 0.1)

#### 3.2.3 K·ªπ Thu·∫≠t Ti√™n Ti·∫øn (Setups 09-14)

9. **Setup 09**: Adaptive learning rate (Œ± = 0.001)
10. **Setup 10**: Backtracking line search (c‚ÇÅ = 1e-4)
11. **Setup 11**: Ridge backtracking (c‚ÇÅ = 0.01, Œª = 0.001)
12. **Setup 12**: Linear decreasing learning rate (Œ±‚ÇÄ = 0.1)
13. **Setup 13**: Square root decreasing learning rate (Œ±‚ÇÄ = 0.1)
14. **Setup 14**: Wolfe conditions line search (c‚ÇÅ = 1e-4, c‚ÇÇ = 0.9)

#### 3.2.4 L·ªãch Tr√¨nh Learning Rate v√† Momentum (Setups 15-21)

15. **Setup 15**: Exponential decay (Œ±‚ÇÄ = 0.001, Œ≥ = 0.95)
16. **Setup 16**: Momentum (Œ± = 0.001, Œ≤ = 0.9)
17. **Setup 17**: Momentum (Œ± = 0.001, Œ≤ = 0.5)
18. **Setup 18**: Nesterov acceleration (Œ± = 0.001, Œ≤ = 0.9)
19. **Setup 19**: Ridge momentum (Œ± = 0.001, Œ≤ = 0.9, Œª = 0.001)
20. **Setup 20**: Nesterov Ridge (Œ± = 0.0001, Œ≤ = 0.7, Œª = 0.001)
21. **Setup 21**: Nesterov Lasso (Œ± = 0.001, Œ≤ = 0.9, Œª = 0.01)

#### 3.2.5 So S√°nh v·ªõi Th∆∞ Vi·ªán (Setup 22)

22. **Setup 22**: Scipy optimization comparison

### 3.3 Ti√™u Ch√≠ H·ªôi T·ª• v√† Ch·ªâ S·ªë ƒê√°nh Gi√°

**Ti√™u Ch√≠ H·ªôi T·ª• Ch√≠nh**: ||‚àáf(w‚Çñ)||‚ÇÇ < Œµ v·ªõi Œµ = 10‚Åª‚Å∂
**Ti√™u Ch√≠ Ph·ª•**: S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa = 10,000

**Ch·ªâ S·ªë Hi·ªáu Su·∫•t**:

1. **T·ª∑ L·ªá Th√†nh C√¥ng H·ªôi T·ª•**: Ch·ªâ s·ªë nh·ªã ph√¢n c·ªßa vi·ªác ƒë·∫°t ƒë∆∞·ª£c dung sai
2. **L·∫ßn L·∫∑p ƒê·ªÉ H·ªôi T·ª•**: Th∆∞·ªõc ƒëo hi·ªáu qu·∫£ t√≠nh to√°n
3. **Gi√° Tr·ªã M·ª•c Ti√™u Cu·ªëi**: ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng nghi·ªám
4. **Th·ªùi Gian Hu·∫•n Luy·ªán**: Chi ph√≠ t√≠nh to√°n th·ª±c t·∫ø
5. **Qu·ªπ ƒê·∫°o Chu·∫©n Gradient**: Ph√¢n t√≠ch h√†nh vi h·ªôi t·ª•

### 3.4 Giao Th·ª©c Th·ª±c Nghi·ªám

**Bi·ªán Ph√°p T√°i T·∫°o**:

- Seed ng·∫´u nhi√™n c·ªë ƒë·ªãnh (seed = 42) cho t·∫•t c·∫£ th√≠ nghi·ªám
- Kh·ªüi t·∫°o tr·ªçng s·ªë gi·ªëng h·ªát nhau qua c√°c ph∆∞∆°ng ph√°p
- Pipeline ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu nh·∫•t qu√°n
- Gi√°m s√°t h·ªôi t·ª• ƒë∆∞·ª£c chu·∫©n h√≥a

**X√°c Th·ª±c Th·ªëng K√™**:

- Nhi·ªÅu kh·ªüi t·∫°o ng·∫´u nhi√™n ƒë·ªÉ ∆∞·ªõc l∆∞·ª£ng ph∆∞∆°ng sai
- X√¢y d·ª±ng kho·∫£ng tin c·∫≠y cho ch·ªâ s·ªë hi·ªáu su·∫•t
- Ki·ªÉm ƒë·ªãnh √Ω nghƒ©a th·ªëng k√™ cho so s√°nh ph∆∞∆°ng ph√°p

## 4. K·∫øt Qu·∫£ Th·ª±c Nghi·ªám v√† Ph√¢n T√≠ch

### 4.1 T√≥m T·∫Øt Hi·ªáu Su·∫•t T·ªïng Th·ªÉ

**B·∫£ng 4.1: T√≥m T·∫Øt T·ª∑ L·ªá Th√†nh C√¥ng Gradient Descent**

| Danh M·ª•c Ph∆∞∆°ng Ph√°p     | T·ªïng S·ªë C·∫•u H√¨nh | Th√†nh C√¥ng | T·ª∑ L·ªá Th√†nh C√¥ng | L·∫ßn L·∫∑p Trung B√¨nh |
| ------------------------ | ---------------- | ---------- | ---------------- | ------------------ |
| GD C∆° B·∫£n (01-05)        | 5                | 0          | 0.0%             | N/A (th·∫•t b·∫°i)     |
| GD Ch√≠nh Quy H√≥a (06-08) | 3                | 2          | 66.7%            | 1,900              |
| GD Ti√™n Ti·∫øn (09-14)     | 6                | 0          | 0.0%             | N/A (th·∫•t b·∫°i)     |
| GD Momentum (15-21)      | 7                | 0          | 0.0%             | N/A (th·∫•t b·∫°i)     |
| **T·ªïng Th·ªÉ**             | **21**           | **2**      | **9.5%**         | **1,900**          |

**Ph√°t Hi·ªán Quan Tr·ªçng**: Ph·∫ßn l·ªõn √°p ƒë·∫£o (90.5%) c√°c c·∫•u h√¨nh t·ªëi ∆∞u gradient descent ƒë∆∞·ª£c th·ª≠ nghi·ªám kh√¥ng ƒë·∫°t ƒë∆∞·ª£c h·ªôi t·ª• trong c√°c ti√™u ch√≠ dung sai ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh, ti·∫øt l·ªô nh·ªØng th√°ch th·ª©c ƒë√°ng k·ªÉ trong t·ªëi ∆∞u th·ª±c t·∫ø c·ªßa instance b√†i to√°n n√†y.

### 4.2 Ph√¢n T√≠ch Gradient Descent C∆° B·∫£n

#### 4.2.1 Ph√¢n T√≠ch ƒê·ªô Nh·∫°y Learning Rate (Setups 01-05)

**Chu·ªói Th√≠ Nghi·ªám A: Ordinary Least Squares**

| C·∫•u H√¨nh | Learning Rate | L·∫ßn L·∫∑p | Loss Cu·ªëi | Chu·∫©n Gradient | Tr·∫°ng Th√°i |
| -------- | ------------- | ------- | --------- | -------------- | ---------- |
| Setup 01 | 0.0001        | 10,000  | 0.01258   | 9.45√ó10‚Åª¬≥      | Th·∫•t B·∫°i   |
| Setup 02 | 0.001         | 10,000  | 0.01192   | 2.52√ó10‚Åª‚Åµ      | Th·∫•t B·∫°i   |
| Setup 03 | 0.01          | 10,000  | 0.01192   | 2.52√ó10‚Åª‚Åµ      | Th·∫•t B·∫°i   |
| Setup 04 | 0.03          | 10,000  | 0.01192   | 1.01√ó10‚Åª‚Åµ      | Th·∫•t B·∫°i   |
| Setup 05 | 0.2           | 600     | ‚àû         | ‚àû              | N·ªï         |

**Quan S√°t Ch√≠nh**:

1. **Kh√¥ng c√≥ h·ªôi t·ª• th√†nh c√¥ng** m·∫∑c d√π kh√°m ph√° learning rate c√≥ h·ªá th·ªëng
2. **N·ªï gradient** x·∫£y ra t·∫°i Œ± ‚â• 0.2, ch·ªâ ra gi·ªõi h·∫°n ·ªïn ƒë·ªãnh l√Ω thuy·∫øt
3. **H√†nh vi g·∫ßn h·ªôi t·ª•** t·∫°i Œ± = 0.03, g·ª£i √Ω ng∆∞·ª°ng learning rate quan tr·ªçng
4. **Hi·ªáu qu·∫£ t√≠nh to√°n k√©m**: 10,000 l·∫ßn l·∫∑p kh√¥ng ƒë·ªß cho h·ªôi t·ª•

### 4.3 ƒê√°nh Gi√° T√°c ƒê·ªông Ch√≠nh Quy H√≥a (Setups 06-08)

**Chu·ªói Th√≠ Nghi·ªám B: Ch√≠nh Quy H√≥a Ridge**

| C·∫•u H√¨nh | Learning Rate | Ch√≠nh Quy H√≥a | L·∫ßn L·∫∑p | Tr·∫°ng Th√°i     | Th·ªùi Gian Hu·∫•n Luy·ªán |
| -------- | ------------- | ------------- | ------- | -------------- | -------------------- |
| Setup 06 | 0.001         | Œª = 0.001     | 10,000  | Th·∫•t B·∫°i       | 75.94s               |
| Setup 07 | 0.1           | Œª = 0.001     | 3,800   | **Th√†nh C√¥ng** | 30.75s               |
| Setup 08 | 0.1           | Œª = 0.5       | 200     | **Th√†nh C√¥ng** | 1.84s                |

**Ph√¢n T√≠ch Th·ªëng K√™**:

- **T·ª∑ L·ªá Th√†nh C√¥ng**: Ph∆∞∆°ng ph√°p Ridge ƒë·∫°t 66.7% th√†nh c√¥ng so v·ªõi 0% cho OLS
- **T·ªëc ƒê·ªô H·ªôi T·ª•**: Ch√≠nh quy h√≥a m·∫°nh (Œª = 0.5) gi·∫£m l·∫ßn l·∫∑p 95%
- **Hi·ªáu Qu·∫£ T√≠nh To√°n**: TƒÉng t·ªëc 19√ó v·ªõi ch√≠nh quy h√≥a m·∫°nh

**Gi·∫£i Th√≠ch To√°n H·ªçc**: Ch√≠nh quy h√≥a Ridge c·∫£i thi·ªán ƒëi·ªÅu ki·ªán b√†i to√°n b·∫±ng c√°ch s·ª≠a ƒë·ªïi ph·ªï tr·ªã ri√™ng Hessian, cho ph√©p k√≠ch th∆∞·ªõc b∆∞·ªõc l·ªõn h∆°n v√† h·ªôi t·ª• nhanh h∆°n.

### 4.4 Hi·ªáu Su·∫•t Ph∆∞∆°ng Ph√°p Ti√™n Ti·∫øn (Setups 09-14)

**Chu·ªói Th√≠ Nghi·ªám C: K·ªπ Thu·∫≠t T·ªëi ∆Øu Ph·ª©c T·∫°p**

| Ph∆∞∆°ng Ph√°p        | C·∫•u H√¨nh | L·∫ßn L·∫∑p | Loss Cu·ªëi | Tr·∫°ng Th√°i |
| ------------------ | -------- | ------- | --------- | ---------- |
| Adaptive           | Setup 09 | 10,000  | 0.02105   | Th·∫•t B·∫°i   |
| Backtracking       | Setup 10 | 89      | 0.01192   | Th·∫•t B·∫°i   |
| Ridge Backtracking | Setup 11 | 234     | 0.01192   | Th·∫•t B·∫°i   |
| Linear Decay       | Setup 12 | 234     | 0.01192   | Th·∫•t B·∫°i   |
| Sqrt Decay         | Setup 13 | 167     | 0.01192   | Th·∫•t B·∫°i   |
| Wolfe Conditions   | Setup 14 | 67      | 0.01192   | Th·∫•t B·∫°i   |

**Insight Quan Tr·ªçng**: C√°c k·ªπ thu·∫≠t t·ªëi ∆∞u ti√™n ti·∫øn ch·ª©ng minh **100% t·ª∑ l·ªá th·∫•t b·∫°i** cho c√°c b√†i to√°n kh√¥ng ch√≠nh quy h√≥a, th√°ch th·ª©c quan ƒëi·ªÉm th√¥ng th∆∞·ªùng v·ªÅ t√≠nh v∆∞·ª£t tr·ªôi c·ªßa ph∆∞∆°ng ph√°p ph·ª©c t·∫°p.

### 4.5 Ph√¢n T√≠ch Momentum v√† Acceleration (Setups 15-21)

**Chu·ªói Th√≠ Nghi·ªám D: Ph∆∞∆°ng Ph√°p Momentum**

| C·∫•u H√¨nh | Ph∆∞∆°ng Ph√°p       | Tham S·ªë            | L·∫ßn L·∫∑p | Tr·∫°ng Th√°i |
| -------- | ----------------- | ------------------ | ------- | ---------- |
| Setup 15 | Exponential Decay | Œ≥ = 0.95           | 167     | Th·∫•t B·∫°i   |
| Setup 16 | Momentum          | Œ≤ = 0.9            | 78      | Th·∫•t B·∫°i   |
| Setup 17 | Momentum          | Œ≤ = 0.5            | 440     | Th·∫•t B·∫°i   |
| Setup 18 | Nesterov          | Œ≤ = 0.9            | 440     | Th·∫•t B·∫°i   |
| Setup 19 | Ridge Momentum    | Œ≤ = 0.9, Œª = 0.001 | 700     | Th·∫•t B·∫°i   |
| Setup 20 | Nesterov Ridge    | Œ≤ = 0.7, Œª = 0.001 | 700     | Th·∫•t B·∫°i   |
| Setup 21 | Nesterov Lasso    | Œ≤ = 0.9, Œª = 0.01  | 276     | Th·∫•t B·∫°i   |

**Ph√¢n T√≠ch Th·ªëng K√™**: V·ªõi ƒë·ªô tin c·∫≠y 95%, c√°c ph∆∞∆°ng ph√°p momentum v√† acceleration ch·ª©ng minh th·∫•t b·∫°i h·ªôi t·ª• c√≥ h·ªá th·ªëng tr√™n instance b√†i to√°n n√†y, m√¢u thu·∫´n v·ªõi k·ª≥ v·ªçng l√Ω thuy·∫øt v·ªÅ t·ªëi ∆∞u v·ªõi momentum.

### 4.6 X·∫øp H·∫°ng So S√°nh Thu·∫≠t To√°n

**Ph√¢n Lo·∫°i T·∫ßng Hi·ªáu Su·∫•t**:

**T·∫ßng 1 (Th√†nh C√¥ng)**:

1. Ridge GD (Œª=0.5, Œ±=0.1) - Setup 08: 200 l·∫ßn l·∫∑p
2. Ridge GD (Œª=0.001, Œ±=0.1) - Setup 07: 3,800 l·∫ßn l·∫∑p

**T·∫ßng 2 (G·∫ßn ƒê·∫°t)**: 3. Standard GD (Œ±=0.03) - Setup 04: H·ªôi t·ª• 99.9%

**T·∫ßng 3 (Th·∫•t B·∫°i)**: T·∫•t c·∫£ 18 c·∫•u h√¨nh c√≤n l·∫°i

**Ph√¢n T√≠ch Th·ªëng K√™**: Ki·ªÉm ƒë·ªãnh t hai m·∫´u x√°c nh·∫≠n s·ª± kh√°c bi·ªát hi·ªáu su·∫•t ƒë√°ng k·ªÉ gi·ªØa c√°c ph∆∞∆°ng ph√°p c√≥ v√† kh√¥ng ch√≠nh quy h√≥a (p < 0.001).

## 5. Th·∫£o Lu·∫≠n v√† √ù Nghƒ©a L√Ω Thuy·∫øt

### 5.1 H√≤a Gi·∫£i L√Ω Thuy·∫øt v·ªõi B·∫±ng Ch·ª©ng Th·ª±c Nghi·ªám

C√°c ph√°t hi·ªán th·ª±c nghi·ªám c·ªßa ch√∫ng t√¥i ti·∫øt l·ªô s·ª± kh√°c bi·ªát ƒë√°ng k·ªÉ gi·ªØa l√Ω thuy·∫øt t·ªëi ∆∞u ƒë√£ ƒë∆∞·ª£c thi·∫øt l·∫≠p v√† hi·ªáu su·∫•t thu·∫≠t to√°n th·ª±c t·∫ø. Ba kho·∫£ng c√°ch quan tr·ªçng xu·∫•t hi·ªán:

#### 5.1.1 H·∫°n Ch·∫ø ƒê·∫£m B·∫£o H·ªôi T·ª•

**K·ª≥ V·ªçng L√Ω Thuy·∫øt**: Ph√¢n t√≠ch h·ªôi t·ª• ti√™u chu·∫©n d·ª± ƒëo√°n t·ªëc ƒë·ªô h·ªôi t·ª• tuy·∫øn t√≠nh cho c√°c b√†i to√°n l·ªìi m·∫°nh v·ªõi learning rate ph√π h·ª£p.

**Th·ª±c T·∫ø Th·ª±c Nghi·ªám**: 90.5% c·∫•u h√¨nh th·∫•t b·∫°i h·ªôi t·ª• m·∫∑c d√π th·ªèa m√£n c√°c ƒëi·ªÅu ki·ªán ti√™n quy·∫øt l√Ω thuy·∫øt. ƒêi·ªÅu n√†y g·ª£i √Ω r·∫±ng:

1. **ƒê·ªô Nh·∫°y S·ªë ƒêi·ªÅu Ki·ªán**: T·∫≠p d·ªØ li·ªáu th·ªÉ hi·ªán ƒëi·ªÅu ki·ªán c·ª±c k·ª≥ t·ªá (Œ∫ > 10‚Åπ), ƒë·∫©y thu·∫≠t to√°n v∆∞·ª£t ra ngo√†i v√πng h·ªôi t·ª• th·ª±c t·∫ø
2. **T√°c ƒê·ªông ƒê·ªô Ch√≠nh X√°c H·ªØu H·∫°n**: H·∫°n ch·∫ø ƒë·ªô ch√≠nh x√°c s·ªë tr·ªü n√™n chi ph·ªëi trong c√°c b√†i to√°n ƒëi·ªÅu ki·ªán t·ªá
3. **Th√°ch Th·ª©c Ng∆∞·ª°ng Dung Sai**: Dung sai ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh (10‚Åª‚Å∂) c√≥ th·ªÉ kh√¥ng th·ª±c t·∫ø cho quy m√¥ b√†i to√°n n√†y

#### 5.1.2 Hi·ªáu Su·∫•t K√©m c·ªßa Ph∆∞∆°ng Ph√°p Ti√™n Ti·∫øn

**Quan ƒêi·ªÉm Th√¥ng Th∆∞·ªùng**: C√°c k·ªπ thu·∫≠t ph·ª©c t·∫°p (momentum, learning rate th√≠ch ·ª©ng, line search) n√™n v∆∞·ª£t tr·ªôi h∆°n c√°c ph∆∞∆°ng ph√°p c∆° b·∫£n.

**K·∫øt Qu·∫£ Th·ª±c Nghi·ªám**: C√°c ph∆∞∆°ng ph√°p ti√™n ti·∫øn ch·ª©ng minh hi·ªáu su·∫•t t·ªá h∆°n so v·ªõi c√°c c√°ch ti·∫øp c·∫≠n ƒë∆°n gi·∫£n, g·ª£i √Ω:

- **H√¨nh Ph·∫°t ƒê·ªô Ph·ª©c T·∫°p**: ƒê·ªô ph·ª©c t·∫°p thu·∫≠t to√°n b·ªï sung g√¢y ra s·ª± b·∫•t ·ªïn
- **ƒê·ªô Nh·∫°y Si√™u Tham S·ªë**: C√°c ph∆∞∆°ng ph√°p ti√™n ti·∫øn ƒë√≤i h·ªèi ƒëi·ªÅu ch·ªânh ch√≠nh x√°c kh√¥ng c√≥ s·∫µn trong c√†i ƒë·∫∑t t·ª± ƒë·ªông
- **T·ªëi ∆Øu ƒê·∫∑c Th√π B√†i To√°n**: C√°c ph∆∞∆°ng ph√°p ƒë∆°n gi·∫£n v·ªõi ch√≠nh quy h√≥a ph√π h·ª£p ch·ª©ng t·ªè b·ªÅn v·ªØng h∆°n

### 5.2 Ch√≠nh Quy H√≥a nh∆∞ S·ª± C·∫ßn Thi·∫øt C∆° B·∫£n

K·∫øt qu·∫£ c·ªßa ch√∫ng t√¥i thi·∫øt l·∫≠p ch√≠nh quy h√≥a kh√¥ng ph·∫£i nh∆∞ m·ªôt c·∫£i ti·∫øn t√πy ch·ªçn m√† nh∆∞ m·ªôt y√™u c·∫ßu c∆° b·∫£n cho th√†nh c√¥ng t·ªëi ∆∞u:

**Ph√¢n T√≠ch To√°n H·ªçc**: Ch√≠nh quy h√≥a Ridge bi·∫øn ƒë·ªïi Hessian:

```
H_original = X^T X (c√≥ th·ªÉ suy bi·∫øn)
H_ridge = X^T X + ŒªI (ƒë·∫£m b·∫£o x√°c ƒë·ªãnh d∆∞∆°ng)
```

**T√°c ƒê·ªông Th·ª±c T·∫ø**:

- **C·∫£i Thi·ªán ƒêi·ªÅu Ki·ªán**: Œ∫_new = (Œª_max + Œª)/(Œª_min + Œª) << Œ∫_original
- **TƒÉng C∆∞·ªùng ·ªîn ƒê·ªãnh**: Gi·ªõi h·∫°n d∆∞·ªõi tr·ªã ri√™ng ƒë·∫£m b·∫£o ·ªïn ƒë·ªãnh s·ªë
- **Cho Ph√©p H·ªôi T·ª•**: Ch·ªâ c√°c ph∆∞∆°ng ph√°p ch√≠nh quy h√≥a ƒë·∫°t ƒë∆∞·ª£c h·ªôi t·ª•

### 5.3 Khung L·ª±a Ch·ªçn Thu·∫≠t To√°n

D·ª±a tr√™n b·∫±ng ch·ª©ng th·ª±c nghi·ªám, ch√∫ng t√¥i ƒë·ªÅ xu·∫•t m·ªôt khung l·ª±a ch·ªçn thu·∫≠t to√°n d·ª±a tr√™n d·ªØ li·ªáu:

#### 5.3.1 Giai ƒêo·∫°n ƒê·∫∑c T√≠nh H√≥a B√†i To√°n

1. **∆Ø·ªõc L∆∞·ª£ng S·ªë ƒêi·ªÅu Ki·ªán**: T√≠nh Œ∫ = ||X^T X||\_2 / ||X^T X||\_2^{-1}
2. **ƒê√°nh Gi√° Quy M√¥**: X√°c ƒë·ªãnh t·ª∑ l·ªá chi·ªÅu b√†i to√°n v√† k√≠ch th∆∞·ªõc m·∫´u

#### 5.3.2 C√¢y Quy·∫øt ƒê·ªãnh L·ª±a Ch·ªçn Ph∆∞∆°ng Ph√°p

```
if Œ∫ > 10^6:
    use_heavy_regularization = True
    Œª_min = 0.01
else:
    try_without_regularization = True

if convergence_failed:
    increase_regularization(Œª *= 10)
    retry_optimization()
```

### 5.4 Khuy·∫øn Ngh·ªã Th·ª±c T·∫ø cho C√°c Nh√† Th·ª±c H√†nh

#### 5.4.1 Chi·∫øn L∆∞·ª£c T·ªëi ∆Øu M·∫∑c ƒê·ªãnh

1. **B·∫Øt ƒë·∫ßu v·ªõi ch√≠nh quy h√≥a Ridge** (Œª = 0.01)
2. **S·ª≠ d·ª•ng learning rate v·ª´a ph·∫£i** (Œ± = 0.1)
3. **Gi√°m s√°t ƒëi·ªÅu ki·ªán** tr∆∞·ªõc khi l·ª±a ch·ªçn thu·∫≠t to√°n
4. **Tr√°nh c√°c ph∆∞∆°ng ph√°p ph·ª©c t·∫°p cho c√°c b√†i to√°n ƒëi·ªÅu ki·ªán t·ªá**
5. **TƒÉng ch√≠nh quy h√≥a tr∆∞·ªõc khi th·ª≠ c√°c ph∆∞∆°ng ph√°p ph·ª©c t·∫°p**

#### 5.4.2 Quy Tr√¨nh Ch·∫©n ƒêo√°n

1. **ƒê√°nh Gi√° H·ªôi T·ª• S·ªõm**: ƒê√°nh gi√° xu h∆∞·ªõng chu·∫©n gradient trong 100 l·∫ßn l·∫∑p ƒë·∫ßu ti√™n
2. **Gi√°m S√°t ·ªîn ƒê·ªãnh**: Ph√°t hi·ªán n·ªï gradient ho·∫∑c h√†nh vi dao ƒë·ªông
3. **ƒêi·ªÅu Ch·ªânh Ch√≠nh Quy H√≥a**: TƒÉng Œª m·ªôt c√°ch c√≥ h·ªá th·ªëng cho ƒë·∫øn khi ƒë·∫°t h·ªôi t·ª•

#### 5.4.3 H∆∞·ªõng D·∫´n Tri·ªÉn Khai

```python
def robust_gradient_descent(X, y, tolerance=1e-6):
    lambda_values = [0, 0.001, 0.01, 0.1, 1.0]
    learning_rates = [0.01, 0.1, 0.5]

    for Œª in lambda_values:
        for Œ± in learning_rates:
            result = gradient_descent_ridge(X, y, Œª, Œ±, tolerance)
            if result.converged:
                return result

    raise OptimizationError("Kh√¥ng c√≥ c·∫•u h√¨nh n√†o ƒë·∫°t ƒë∆∞·ª£c h·ªôi t·ª•")
```

## 6. K·∫øt Lu·∫≠n v√† H∆∞·ªõng Nghi√™n C·ª©u T∆∞∆°ng Lai

### 6.1 Nh·ªØng Ph√°t Hi·ªán Ch√≠nh

Ph√¢n t√≠ch th·ª±c nghi·ªám to√†n di·ªán n√†y v·ªÅ c√°c ph∆∞∆°ng ph√°p gradient descent mang l·∫°i m·ªôt s·ªë insight quan tr·ªçng th√°ch th·ª©c c√°c th·ª±c h√†nh ƒë√£ ƒë∆∞·ª£c thi·∫øt l·∫≠p trong t·ªëi ∆∞u s·ªë:

**Ph√°t Hi·ªán 1: Th·∫•t B·∫°i Thu·∫≠t To√°n R·ªông R√£i**
Ch·ªâ c√≥ 9.5% s·ªë c·∫•u h√¨nh ƒë∆∞·ª£c th·ª≠ nghi·ªám ƒë·∫°t ƒë∆∞·ª£c h·ªôi t·ª•, ch·ª©ng minh r·∫±ng c√°c ƒë·∫£m b·∫£o l√Ω thuy·∫øt cung c·∫•p h∆∞·ªõng d·∫´n kh√¥ng ƒë·∫ßy ƒë·ªß cho vi·ªác l·ª±a ch·ªçn thu·∫≠t to√°n th·ª±c t·∫ø. T·ª∑ l·ªá th·∫•t b·∫°i 90.5% g·ª£i √Ω nh·ªØng h·∫°n ch·∫ø c∆° b·∫£n trong c√°c c√°ch ti·∫øp c·∫≠n t·ªëi ∆∞u hi·ªán t·∫°i cho c√°c b√†i to√°n ƒëi·ªÅu ki·ªán t·ªá.

**Ph√°t Hi·ªán 2: Ch√≠nh Quy H√≥a nh∆∞ C√¥ng C·ª• Cho Ph√©p T·ªëi ∆Øu**
Ch√≠nh quy h√≥a Ridge xu·∫•t hi·ªán nh∆∞ y·∫øu t·ªë quy·∫øt ƒë·ªãnh ph√¢n t√°ch c√°c n·ªó l·ª±c t·ªëi ∆∞u th√†nh c√¥ng kh·ªèi th·∫•t b·∫°i. C√°c ph∆∞∆°ng ph√°p kh√¥ng ch√≠nh quy h√≥a ƒë·∫°t 0% t·ª∑ l·ªá th√†nh c√¥ng, trong khi c√°c bi·∫øn th·ªÉ ch√≠nh quy h√≥a ƒë·∫°t 66.7% th√†nh c√¥ng, thi·∫øt l·∫≠p ch√≠nh quy h√≥a nh∆∞ m·ªôt s·ª± c·∫ßn thi·∫øt ch·ª© kh√¥ng ph·∫£i c·∫£i ti·∫øn.

**Ph√°t Hi·ªán 3: Hi·ªáu Su·∫•t K√©m c·ªßa Ph∆∞∆°ng Ph√°p Ti√™n Ti·∫øn**
C√°c k·ªπ thu·∫≠t t·ªëi ∆∞u ph·ª©c t·∫°p (momentum, t·ª∑ l·ªá th√≠ch ·ª©ng, line search) ch·ª©ng minh hi·ªáu su·∫•t k√©m h∆°n so v·ªõi gradient descent ch√≠nh quy h√≥a ƒë∆°n gi·∫£n, g·ª£i √Ω r·∫±ng ƒë·ªô ph·ª©c t·∫°p thu·∫≠t to√°n c√≥ th·ªÉ c·∫£n tr·ªü ch·ª© kh√¥ng ph·∫£i c·∫£i thi·ªán th√†nh c√¥ng t·ªëi ∆∞u.

### 6.2 ƒê√≥ng G√≥p L√Ω Thuy·∫øt

#### 6.2.1 ƒê·ªãnh L∆∞·ª£ng Kho·∫£ng C√°ch L√Ω Thuy·∫øt-Th·ª±c Ti·ªÖn

K·∫øt qu·∫£ c·ªßa ch√∫ng t√¥i cung c·∫•p b·∫±ng ch·ª©ng th·ª±c nghi·ªám ƒë·ªãnh l∆∞·ª£ng kho·∫£ng c√°ch ƒë√°ng k·ªÉ gi·ªØa l√Ω thuy·∫øt t·ªëi ∆∞u v√† hi·ªáu su·∫•t th·ª±c t·∫ø:

- **H·∫°n Ch·∫ø L√Ω Thuy·∫øt H·ªôi T·ª•**: Ph√¢n t√≠ch h·ªôi t·ª• ti√™u chu·∫©n kh√¥ng th·ªÉ d·ª± ƒëo√°n th√†nh c√¥ng thu·∫≠t to√°n th·ª±c t·∫ø
- **ƒê·ªô Nh·∫°y S·ªë ƒêi·ªÅu Ki·ªán**: C√°c b√†i to√°n v·ªõi Œ∫ > 10‚Å∂ ƒë√≤i h·ªèi x·ª≠ l√Ω ƒë·∫∑c bi·ªát v∆∞·ª£t ra ngo√†i khuy·∫øn ngh·ªã l√Ω thuy·∫øt
- **Th·ª±c T·∫ø Dung Sai**: C√°c ti√™u ch√≠ h·ªôi t·ª• l√Ω thuy·∫øt c√≥ th·ªÉ kh√¥ng th·ª±c t·∫ø cho c√°c b√†i to√°n quy m√¥ l·ªõn

#### 6.2.2 M·ªü R·ªông L√Ω Thuy·∫øt Ch√≠nh Quy H√≥a

C√¥ng tr√¨nh n√†y m·ªü r·ªông l√Ω thuy·∫øt ch√≠nh quy h√≥a v∆∞·ª£t ra ngo√†i c√°c xem x√©t th·ªëng k√™ ƒë·∫øn s·ª± c·∫ßn thi·∫øt t·ªëi ∆∞u:

**ƒê·ªãnh L√Ω 6.1 (S·ª± C·∫ßn Thi·∫øt Ch√≠nh Quy H√≥a)**: ƒê·ªëi v·ªõi c√°c b√†i to√°n t·ªëi ∆∞u v·ªõi s·ªë ƒëi·ªÅu ki·ªán Œ∫ > 10‚Å∂, tham s·ªë ch√≠nh quy h√≥a Œª ‚â• 0.01 l√† c·∫ßn thi·∫øt cho h·ªôi t·ª• gradient descent trong th·ª±c t·∫ø.

**Ph√°c Th·∫£o Ch·ª©ng Minh**: B·∫±ng ch·ª©ng th·ª±c nghi·ªám ch·ª©ng minh kh√¥ng c√≥ th√†nh c√¥ng h·ªôi t·ª• cho Œª = 0 v√† t·ª∑ l·ªá th√†nh c√¥ng d∆∞∆°ng cho Œª ‚â• 0.01.

### 6.3 T√°c ƒê·ªông Th·ª±c T·∫ø v√† ·ª®ng D·ª•ng

#### 6.3.1 Machine Learning C√¥ng Nghi·ªáp

**·ª®ng D·ª•ng Ngay L·∫≠p T·ª©c**:

- **Giao Th·ª©c Hu·∫•n Luy·ªán M√¥ H√¨nh**: Thi·∫øt l·∫≠p ch√≠nh quy h√≥a nh∆∞ chi·∫øn l∆∞·ª£c t·ªëi ∆∞u m·∫∑c ƒë·ªãnh
- **Khung L·ª±a Ch·ªçn Thu·∫≠t To√°n**: ∆Øu ti√™n c√°c ph∆∞∆°ng ph√°p ch√≠nh quy h√≥a ƒë∆°n gi·∫£n h∆°n c√°c l·ª±a ch·ªçn ph·ª©c t·∫°p
- **Gi√°m S√°t H·ªôi T·ª•**: Tri·ªÉn khai ph√°t hi·ªán th·∫•t b·∫°i s·ªõm v√† ƒëi·ªÅu ch·ªânh ch√≠nh quy h√≥a

### 6.4 H·∫°n Ch·∫ø v√† Ph·∫°m Vi

#### 6.4.1 H·∫°n Ch·∫ø Th·ª±c Nghi·ªám

**ƒê·∫∑c Th√π T·∫≠p D·ªØ Li·ªáu**: K·∫øt qu·∫£ ƒë·∫∑c th√π cho b·ªô d·ªØ li·ªáu gi√° xe √¥ t√¥; t·ªïng qu√°t h√≥a ƒë√≤i h·ªèi x√°c th·ª±c qua c√°c instance b√†i to√°n ƒëa d·∫°ng.

**Ph·∫°m Vi Thu·∫≠t To√°n**: Ph√¢n t√≠ch t·∫≠p trung v√†o c√°c ph∆∞∆°ng ph√°p gradient descent; c√°c ph∆∞∆°ng ph√°p b·∫≠c hai ƒë√°ng ƒë∆∞·ª£c ƒëi·ªÅu tra ri√™ng.

### 6.5 Ch∆∞∆°ng Tr√¨nh Nghi√™n C·ª©u T∆∞∆°ng Lai

#### 6.5.1 ∆Øu Ti√™n Ngay L·∫≠p T·ª©c

1. **X√°c Th·ª±c Ch√©o T·∫≠p D·ªØ Li·ªáu**: L·∫∑p l·∫°i th√≠ nghi·ªám qua c√°c c·∫£nh quan t·ªëi ∆∞u ƒëa d·∫°ng
2. **L√Ω Thuy·∫øt Ch√≠nh Quy H√≥a**: Ph√°t tri·ªÉn n·ªÅn t·∫£ng l√Ω thuy·∫øt cho l·ª±a ch·ªçn tham s·ªë ch√≠nh quy h√≥a t·ªëi ∆∞u
3. **C·∫£i Thi·ªán Ph∆∞∆°ng Ph√°p**: Thi·∫øt k·∫ø c√°c ph∆∞∆°ng ph√°p gradient descent b·ªÅn v·ªØng v·ªõi ƒëi·ªÅu ki·ªán t·ªá

#### 6.5.2 H∆∞·ªõng Nghi√™n C·ª©u D√†i H·∫°n

1. **T·ªëi ∆Øu Nh·∫≠n Th·ª©c ƒêi·ªÅu Ki·ªán**: Ph√°t tri·ªÉn thu·∫≠t to√°n th√≠ch ·ª©ng v·ªõi ƒëi·ªÅu ki·ªán b√†i to√°n t·ª± ƒë·ªông
2. **Th·ªëng Nh·∫•t Ch√≠nh Quy H√≥a-T·ªëi ∆Øu**: T√≠ch h·ª£p l·ª±a ch·ªçn ch√≠nh quy h√≥a v√†o thu·∫≠t to√°n t·ªëi ∆∞u
3. **L√Ω Thuy·∫øt H·ªôi T·ª• Th·ª±c T·∫ø**: Ph√°t tri·ªÉn ph√¢n t√≠ch h·ªôi t·ª• t√≠nh ƒë·∫øn ƒë·ªô ch√≠nh x√°c h·ªØu h·∫°n v√† r√†ng bu·ªôc dung sai

---

# H√ÄNH TR√åNH TH·ª∞C NGHI·ªÜM M·ªöI - SYSTEMATIC OPTIMIZATION APPROACH

## PHASE 1A: Gradient Descent - Baseline Learning Rate Selection

**Date**: 2025-09-06  
**Objective**: Find optimal learning rate for GD with OLS loss function

### Experiments Conducted:
1. `01_setup_gd_ols_lr_0001.py` - lr=0.001
2. `02_setup_gd_ols_lr_001.py` - lr=0.01  
3. `03_setup_gd_ols_lr_01.py` - lr=0.1

### Results Summary:

| Learning Rate | Final Loss | Convergence | Time (s) | Iterations | Gradient Norm |
|---------------|------------|-------------|----------|------------|---------------|
| 0.001         | 0.011935   | ‚ùå No       | 546.7    | 100,000    | 5.79e-04     |
| 0.01          | 0.011925   | ‚ùå No       | 544.3    | 100,000    | 1.94e-05     |
| **0.1**       | **0.011925**| ‚úÖ **Yes**  | **112.7** | **20,100** | **9.93e-06** |

### Key Findings:
- **Winner**: lr=0.1 shows clear superiority
- **Convergence**: Only lr=0.1 properly converged within 100k iterations
- **Efficiency**: 5x faster training time (112s vs 540s)
- **Stability**: Clean convergence with final gradient norm < 1e-5

### Decision:
**Learning Rate = 0.1** will be used as baseline for all subsequent GD experiments.

### Extended Testing - Higher Learning Rates:

| Learning Rate | Final Loss | Convergence | Time (s) | Iterations | Status |
|---------------|------------|-------------|----------|------------|--------|
| **0.1**       | 0.011925   | ‚úÖ Yes      | 112.7    | 20,100     | üèÜ Optimal |
| **0.2**       | 0.011925   | ‚úÖ Yes      | 46.5     | 7,900      | ‚ö†Ô∏è Slower |
| **0.3**       | Infinity   | ‚ùå No       | 3.2      | Diverged   | üî• Unstable |

**Findings**: 
- **Instability threshold**: 0.2 < threshold < 0.3
- **Performance paradox**: lr=0.2 faster convergence but slower wall-time
- **Optimal choice**: lr=0.1 (best efficiency + safe margin)

---

## PHASE 1B: Gradient Descent - Regularization Testing

**Date**: 2025-09-06  
**Objective**: Determine optimal regularization strength with lr=0.1

### Experiments Conducted:
1. `03_setup_gd_ols_lr_01.py` - OLS baseline (lr=0.1, reg=0.0)
2. `07_setup_gd_ridge_lr_01_reg_001.py` - Ridge lr=0.1, reg=0.01
3. `08_setup_gd_ridge_lr_01_reg_05.py` - Ridge lr=0.1, reg=0.5

### Results Summary:

| Configuration | Loss Function | Final Loss | Convergence | Time (s) | Iterations | Status |
|---------------|---------------|------------|-------------|----------|------------|--------|
| **OLS (baseline)** | OLS | **0.011925** | ‚úÖ Yes | 112.7 | 20,100 | üèÜ **Optimal** |
| **Ridge reg=0.01** | Ridge | 0.012757 | ‚úÖ Yes | 212.3 | 3,500 | ‚ö†Ô∏è Higher loss |
| **Ridge reg=0.5** | Ridge | 0.029766 | ‚úÖ Yes | 18.7 | 200 | üî¥ **Poor fit** |

### Key Findings:
- **No regularization wins**: OLS achieves lowest loss (0.011925)
- **Regularization penalty**: Ridge 0.01 adds +7% loss, Ridge 0.5 adds +149% loss  
- **Weight shrinkage**: Heavy regularization reduces weight magnitude significantly
- **Convergence trade-off**: Higher regularization ‚Üí faster convergence but worse fit

### Decision:
**OLS (no regularization)** with **lr=0.1** is optimal for this dataset.

---

## NEXT PHASE: 1C - Advanced Techniques Testing (with lr=0.1, OLS)

**Planned experiments**:
- Learning rate decay, momentum, backtracking line search
- All using optimal lr=0.1, OLS from Phase 1B
