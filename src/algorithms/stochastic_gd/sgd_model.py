#!/usr/bin/env python3
"""
SGDModel - Class cho Stochastic Gradient Descent
H·ªó tr·ª£ c√°c loss functions: MSE (Mean Squared Error)
"""

import pandas as pd
import numpy as np
from pathlib import Path
import time
import sys
import os
import json
import pickle

# Add the src directory to path ƒë·ªÉ import utils
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from utils.optimization_utils import (
    du_doan, danh_gia_mo_hinh, in_ket_qua_danh_gia, kiem_tra_dieu_kien_dung,
    tinh_gia_tri_ham_loss, tinh_gradient_ham_loss, tinh_hessian_ham_loss,
    add_bias_column
)
from utils.visualization_utils import (
    ve_duong_hoi_tu, ve_du_doan_vs_thuc_te, ve_duong_dong_muc_optimization
)


class SGDModel:
    """   
    Stochastic Gradient Descent v·ªõi h·ªó tr·ª£:
    - Multiple learning rate schedules
    - Batch processing v·ªõi size t√πy ch·ªçn
    - Momentum support
    - Enhanced shuffling strategies
    - Computational complexity tracking
    
    Parameters:
    - ham_loss: 'ols', 'ridge', 'lasso'  
    - learning_rate: T·ª∑ l·ªá h·ªçc ban ƒë·∫ßu
    - so_epochs: S·ªë epochs t·ªëi ƒëa
    - batch_size: K√≠ch th∆∞·ªõc batch
    - diem_dung: Ng∆∞·ª°ng h·ªôi t·ª•
    - learning_rate_schedule: Ph∆∞∆°ng ph√°p ƒëi·ªÅu ch·ªânh learning rate
    - momentum: H·ªá s·ªë momentum (0 = kh√¥ng d√πng momentum)
    - convergence_check_freq: T·∫ßn su·∫•t ki·ªÉm tra h·ªôi t·ª• (m·ªói N epochs)
    - shuffle_each_epoch: Enhanced shuffling v·ªõi seed m·ªõi m·ªói epoch
    - randomize_each_epoch: Full randomization v·ªõi replacement m·ªói epoch
    """
    
    def __init__(self, ham_loss='ols', learning_rate=0.01, so_epochs=100, batch_size=32, 
                 diem_dung=1e-5, regularization=0.01, learning_rate_schedule='constant',
                 momentum=0.0, convergence_check_freq=10, random_state=42,
                 # Enhanced shuffling strategies
                 shuffle_each_epoch=False, randomize_each_epoch=False,
                 # Learning rate schedule parameters
                 decay_rate=0.95, decay_steps=100,
                 # Fixed step length option
                 use_fixed_step_length=False, step_length=0.01):
        
        self.ham_loss = ham_loss.lower()
        self.learning_rate = learning_rate
        self.so_epochs = so_epochs
        self.batch_size = batch_size
        self.diem_dung = diem_dung
        self.regularization = regularization
        self.learning_rate_schedule = learning_rate_schedule
        self.momentum = momentum
        self.use_momentum = momentum > 0
        self.convergence_check_freq = convergence_check_freq
        self.random_state = random_state
        
        # Enhanced shuffling options
        self.shuffle_each_epoch = shuffle_each_epoch
        self.randomize_each_epoch = randomize_each_epoch
        
        # Learning rate schedule parameters
        self.decay_rate = decay_rate
        self.decay_steps = decay_steps
        
        # Fixed step length parameters
        self.use_fixed_step_length = use_fixed_step_length
        self.step_length = step_length
        
        # S·ª≠ d·ª•ng unified functions v·ªõi format m·ªõi (bias trong X)
        self.loss_func = lambda X, y, w: tinh_gia_tri_ham_loss(self.ham_loss, X, y, w, None, self.regularization)
        self.grad_func = lambda X, y, w: tinh_gradient_ham_loss(self.ham_loss, X, y, w, None, self.regularization)
        
        # Initialize attributes to store results
        self.weights = None
        self.velocity = None  # For momentum
        self.loss_history = []
        self.gradient_norms = []
        self.weights_history = []
        self.learning_rates_history = []
        self.training_time = 0
        self.converged = False
        self.final_epoch = 0
        self.final_cost = 0
        
        print(f"SGD Model initialized:")
        print(f"   Loss function: {self.ham_loss.upper()}")
        if self.use_fixed_step_length:
            print(f"   Step length: {self.step_length} (fixed step length mode)")
        else:
            print(f"   Learning rate: {self.learning_rate} ({self.learning_rate_schedule})")
        print(f"   Epochs: {self.so_epochs}, Batch size: {self.batch_size}")
        print(f"   Momentum: {self.momentum}")
        print(f"   Random state: {self.random_state}")
        if self.use_fixed_step_length:
            print(f"   Using fixed step length instead of fixed step size")
        if regularization and ham_loss in ['ridge', 'lasso']:
            print(f"   Regularization: {self.regularization}")

    def _get_best_results(self):
        """
        L·∫•y k·∫øt qu·∫£ t·ªët nh·∫•t d·ª±a tr√™n gradient norm th·∫•p nh·∫•t
        
        Returns:
            dict: Ch·ª©a best_weights, best_loss, best_gradient_norm, best_epoch
        """
        if not self.gradient_norms:
            raise ValueError("Kh√¥ng c√≥ l·ªãch s·ª≠ gradient norms ƒë·ªÉ t√¨m k·∫øt qu·∫£ t·ªët nh·∫•t")
        
        if len(self.gradient_norms) != len(self.weights_history) or len(self.gradient_norms) != len(self.loss_history):
            raise ValueError("L·ªãch s·ª≠ gradient norms, weights v√† loss kh√¥ng c√πng ƒë·ªô d√†i")
        
        # T√¨m index c√≥ gradient norm th·∫•p nh·∫•t
        best_idx = np.argmin(self.gradient_norms)
        
        return {
            'best_weights': self.weights_history[best_idx],
            'best_loss': float(self.loss_history[best_idx]),
            'best_gradient_norm': float(self.gradient_norms[best_idx]),
            'best_epoch': int(best_idx * self.convergence_check_freq)
        }
    
    def _get_learning_rate(self, epoch):
        """
        T√≠nh learning rate theo schedule ƒë∆∞·ª£c ch·ªçn
        
        Args:
            epoch: Epoch hi·ªán t·∫°i (0-indexed)
        """
        if self.learning_rate_schedule == 'constant':
            return self.learning_rate
        elif self.learning_rate_schedule == 'linear_decay':
            # Gi·∫£m tuy·∫øn t√≠nh: lr * (1 - epoch/max_epochs)
            decay_factor = 1.0 - (epoch / max(self.so_epochs, 1))
            return self.learning_rate * max(decay_factor, 0.01)  # Minimum 1% of original
        elif self.learning_rate_schedule == 'exponential_decay':
            # Gi·∫£m exponential: lr * decay_rate^(epoch/decay_steps)
            return self.learning_rate * (self.decay_rate ** (epoch / self.decay_steps))
        elif self.learning_rate_schedule == 'sqrt_decay':
            # Gi·∫£m theo sqrt: lr / sqrt(epoch + 1)
            return self.learning_rate / np.sqrt(epoch + 1)
        elif self.learning_rate_schedule == 'backtracking':
            # Simple backtracking implementation for SGD (placeholder)
            return self.learning_rate * (0.9 ** (epoch // 10))
        else:
            return self.learning_rate
    
    def _tinh_gradient_sample(self, xi, yi, weights):
        """
        T√≠nh gradient cho 1 sample - optimized cho SGD
        
        Args:
            xi: Feature vector for sample i (ƒë√£ c√≥ bias)
            yi: Target value for sample i  
            weights: Weight vector hi·ªán t·∫°i
        """
        # Direct gradient computation for single sample (more efficient)
        if self.ham_loss == 'ols':
            # OLS: gradient = X^T * (X*w - y) / n = xi * (xi^T * w - yi)
            prediction = np.dot(xi, weights)
            residual = prediction - yi
            gradient = residual * xi
        elif self.ham_loss == 'ridge':
            # Ridge: gradient = X^T * (X*w - y) / n + lambda * w
            prediction = np.dot(xi, weights)
            residual = prediction - yi
            gradient = residual * xi + self.regularization * weights
            # Don't regularize bias term (last element)
            gradient[-1] -= self.regularization * weights[-1]  # Remove regularization from bias
        elif self.ham_loss == 'lasso':
            # Lasso: gradient = X^T * (X*w - y) / n + lambda * sign(w)
            prediction = np.dot(xi, weights)
            residual = prediction - yi
            gradient = residual * xi + self.regularization * np.sign(weights)
            # Don't regularize bias term (last element)
            gradient[-1] -= self.regularization * np.sign(weights[-1])  # Remove regularization from bias
        else:
            # Fallback to unified function for other loss functions
            X_sample = xi.reshape(1, -1)
            y_sample = np.array([yi])
            gradient, _ = tinh_gradient_ham_loss(self.ham_loss, X_sample, y_sample, weights, None, self.regularization)
        
        return gradient
    
    def _tinh_chi_phi(self, X, y, weights):
        """
        T√≠nh chi ph√≠ (cost) cho to√†n b·ªô dataset s·ª≠ d·ª•ng unified function
        
        Args:
            X: Feature matrix (ƒë√£ c√≥ bias)
            y: Target vector
            weights: Weight vector
        """
        return self.loss_func(X, y, weights)
    
    def _check_sgd_convergence(self, gradient_norm, cost_change, iteration, epoch_cost, loss_history):
        """
        Ki·ªÉm tra ƒëi·ªÅu ki·ªán d·ª´ng cho SGD v·ªõi enhanced logic
        
        Returns:
            (should_stop, converged, reason)
        """
        # Use unified convergence check with SGD adaptations
        # Adjust tolerance for SGD noise (more lenient)
        sgd_tolerance = self.diem_dung * 10  # 10x more lenient for cost changes
        
        should_stop, converged, reason = kiem_tra_dieu_kien_dung(
            gradient_norm=gradient_norm,
            cost_change=cost_change,
            iteration=iteration,
            tolerance=self.diem_dung,  # Keep original tolerance for gradient
            max_iterations=self.so_epochs,
            loss_value=epoch_cost,
            weights=self.weights
        )
        
        # Additional SGD-specific divergence check
        if not should_stop and len(loss_history) >= 5:
            recent_costs = loss_history[-5:]
            if len(recent_costs) >= 2 and recent_costs[-1] > recent_costs[0] * 2:
                return True, False, "Cost increased significantly (possible divergence in SGD)"
        
        return should_stop, converged, reason
    
    def fit(self, X, y):
        """
        Hu·∫•n luy·ªán model v·ªõi d·ªØ li·ªáu X, y
        
        Returns:
        - dict: K·∫øt qu·∫£ training bao g·ªìm weights, loss_history, etc.
        """
        print(f"Training Stochastic Gradient Descent - {self.ham_loss.upper()}")
        print(f"   Learning rate schedule: {self.learning_rate_schedule} - Base learning rate: {self.learning_rate}")
        print(f"   Epochs: {self.so_epochs}, Batch size: {self.batch_size}")
        print(f"   Random state: {self.random_state}")
        
        if self.shuffle_each_epoch:
            print(f"   Enhanced shuffling: New random seed each epoch")
        if self.randomize_each_epoch:
            print(f"   Full randomization: Sample with replacement each epoch")
        
        if self.momentum > 0 or self.use_momentum:
            print(f"   Using momentum: {self.momentum}")
        
        # Initialize complexity tracker
        from utils.computational_complexity import ComputationalComplexityTracker
        self.complexity_tracker = ComputationalComplexityTracker(
            problem_size=(X.shape[0], X.shape[1])
        )
        self.complexity_tracker.start_tracking()
        
        np.random.seed(self.random_state)
        
        # Th√™m c·ªôt bias v√†o X
        X_with_bias = add_bias_column(X)
        print(f"   Original features: {X.shape[1]}, With bias: {X_with_bias.shape[1]}")
        
        n_samples, n_features_with_bias = X_with_bias.shape
        self.weights = np.random.normal(0, 0.01, n_features_with_bias)
        
        # Track initial memory allocation
        self.complexity_tracker.record_memory_allocation(len(self.weights))
        
        # Initialize velocity for momentum
        if self.momentum > 0 or self.use_momentum:
            self.velocity = np.zeros(n_features_with_bias)
            self.complexity_tracker.record_memory_allocation(len(self.velocity))
        
        # Reset histories
        self.loss_history = []
        self.gradient_norms = []
        self.weights_history = []
        self.learning_rates_history = []
        
        # Add convergence tracking
        self.converged = False
        self.final_epoch = 0
        
        start_time = time.time()
        
        for epoch in range(self.so_epochs):
            # Get learning rate for this epoch
            current_lr = self._get_learning_rate(epoch)
            self.learning_rates_history.append(current_lr)
            
            # Enhanced shuffling/randomization logic
            if self.randomize_each_epoch:
                # Full randomization with replacement - different samples each epoch
                epoch_seed = self.random_state + epoch * 1000  # Different seed each epoch
                np.random.seed(epoch_seed)
                indices = np.random.choice(n_samples, size=n_samples, replace=True)
                X_shuffled = X_with_bias[indices]
                y_shuffled = y[indices]
            elif self.shuffle_each_epoch:
                # Enhanced shuffling - new permutation seed each epoch
                epoch_seed = self.random_state + epoch * 100  # Different seed each epoch
                np.random.seed(epoch_seed)
                indices = np.random.permutation(n_samples)
                X_shuffled = X_with_bias[indices]
                y_shuffled = y[indices]
            else:
                # Standard shuffling (existing behavior)
                indices = np.random.permutation(n_samples)
                X_shuffled = X_with_bias[indices]
                y_shuffled = y[indices]
            
            epoch_gradients = []
            
            # Process in batches
            for i in range(0, n_samples, self.batch_size):
                end_idx = min(i + self.batch_size, n_samples)
                X_batch = X_shuffled[i:end_idx]
                y_batch = y_shuffled[i:end_idx]
                
                # Track batch processing operations
                batch_size_actual = len(X_batch)
                
                # T√≠nh gradient cho batch
                batch_gradient = np.zeros(n_features_with_bias)
                
                for j in range(len(X_batch)):
                    xi = X_batch[j]
                    yi = y_batch[j]
                    sample_gradient = self._tinh_gradient_sample(xi, yi, self.weights)
                    batch_gradient += sample_gradient
                    
                    # Track gradient computation for each sample
                    self.complexity_tracker.record_gradient_evaluation((1, n_features_with_bias))
                    self.complexity_tracker.record_vector_operation(n_features_with_bias, "basic")
                
                # Average gradient over batch
                batch_gradient /= len(X_batch)
                epoch_gradients.append(batch_gradient)
                
                # Track averaging operation
                self.complexity_tracker.record_vector_operation(n_features_with_bias, "basic")
                
                # Update weights with momentum if enabled
                if self.momentum > 0 or self.use_momentum:
                    # Momentum update: v = Œ≤ * v + ‚àáL
                    self.velocity = self.momentum * self.velocity + batch_gradient
                    
                    if self.use_fixed_step_length:
                        # Fixed step length with momentum: normalize velocity then scale
                        velocity_norm = np.linalg.norm(self.velocity)
                        if velocity_norm > 1e-10:  # Avoid division by zero
                            unit_velocity = self.velocity / velocity_norm
                            self.weights -= self.step_length * unit_velocity
                        # else: velocity is zero, no update needed
                    else:
                        # Standard momentum: w = w - Œ± * v
                        self.weights -= current_lr * self.velocity
                    
                    # Track momentum operations
                    self.complexity_tracker.record_vector_operation(n_features_with_bias, "basic")  # momentum update
                    self.complexity_tracker.record_vector_operation(n_features_with_bias, "basic")  # weight update
                    if self.use_fixed_step_length:
                        self.complexity_tracker.record_vector_operation(n_features_with_bias, "norm")  # normalization
                else:
                    if self.use_fixed_step_length:
                        # Fixed step length: normalize gradient then scale
                        gradient_norm = np.linalg.norm(batch_gradient)
                        if gradient_norm > 1e-10:  # Avoid division by zero
                            unit_gradient = batch_gradient / gradient_norm
                            self.weights -= self.step_length * unit_gradient
                        # else: gradient is zero, no update needed
                        
                        # Track fixed step length operations
                        self.complexity_tracker.record_vector_operation(n_features_with_bias, "norm")  # normalization
                        self.complexity_tracker.record_vector_operation(n_features_with_bias, "basic")  # weight update
                    else:
                        # Standard SGD update: w = w - Œ± * ‚àáL
                        self.weights -= current_lr * batch_gradient
                        
                        # Track weight update
                        self.complexity_tracker.record_vector_operation(n_features_with_bias, "basic")
                
                # Track weight copy for history
                self.complexity_tracker.record_memory_allocation(len(self.weights))
            
            # Ch·ªâ t√≠nh cost v√† l∆∞u history khi c·∫ßn thi·∫øt  
            should_log = (
                (epoch + 1) % self.convergence_check_freq == 0 or
                epoch == self.so_epochs - 1 or
                (epoch + 1) % 20 == 0  # Progress logging
            )
            
            if should_log:
                # Ch·ªâ t√≠nh cost khi c·∫ßn (expensive operation)
                epoch_cost = self._tinh_chi_phi(X_with_bias, y, self.weights)
                epoch_gradient_avg = np.mean(epoch_gradients, axis=0)
                gradient_norm = np.linalg.norm(epoch_gradient_avg)
                
                # Track cost and norm computations
                self.complexity_tracker.record_function_evaluation(X_with_bias.shape)
                self.complexity_tracker.record_vector_operation(len(epoch_gradient_avg), "norm")
                
                # L∆∞u v√†o history
                self.loss_history.append(epoch_cost)
                self.gradient_norms.append(gradient_norm)
                self.weights_history.append(self.weights.copy())
            
            # Check convergence v·ªõi t·∫ßn su·∫•t ƒë·ªãnh s·∫µn ho·∫∑c ·ªü epoch cu·ªëi
            if (epoch + 1) % self.convergence_check_freq == 0 or epoch == self.so_epochs - 1:
                # ƒê·∫£m b·∫£o c√≥ gradient_norm v√† epoch_cost cho convergence check
                if not should_log:
                    epoch_cost = self._tinh_chi_phi(X_with_bias, y, self.weights)
                    epoch_gradient_avg = np.mean(epoch_gradients, axis=0)
                    gradient_norm = np.linalg.norm(epoch_gradient_avg)
                    
                    # Track additional computations
                    self.complexity_tracker.record_function_evaluation(X_with_bias.shape)
                    self.complexity_tracker.record_vector_operation(len(epoch_gradient_avg), "norm")
                    
                # Calculate cost change safely
                if len(self.loss_history) <= 1:
                    cost_change = 0.0  # No previous cost to compare
                else:
                    cost_change = self.loss_history[-2] - self.loss_history[-1]  # Previous - current
                
                # Use SGD-specific convergence check
                should_stop, converged, reason = self._check_sgd_convergence(
                    gradient_norm=gradient_norm,
                    cost_change=cost_change,
                    iteration=epoch,
                    epoch_cost=epoch_cost,
                    loss_history=self.loss_history
                )
                
                if should_stop:
                    if converged:
                        print(f"SGD converged: {reason}")
                        self.complexity_tracker.mark_convergence(epoch + 1)
                    else:
                        print(f"SGD stopped (not converged): {reason}")
                    self.converged = converged
                    self.final_epoch = epoch + 1
                    break
            
            # Progress update - ch·ªâ print khi ƒë√£ c√≥ data
            if (epoch + 1) % 20 == 0 and should_log:
                print(f"   Epoch {epoch + 1}: Cost = {epoch_cost:.6f}, Gradient = {gradient_norm:.6f}, LR = {current_lr}")
            
            # End epoch tracking
            self.complexity_tracker.end_iteration()
        
        self.training_time = time.time() - start_time
        self.final_cost = self.loss_history[-1]
        
        if not self.converged:
            print(f"Reached maximum {self.so_epochs} epochs")
            self.final_epoch = self.so_epochs
            
        print(f"Th·ªùi gian training: {self.training_time:.2f}s")
        print(f"Loss cu·ªëi: {self.final_cost:.6f}")
        print(f"Bias cu·ªëi: {self.weights[-1]:.6f}")  # Bias l√† ph·∫ßn t·ª≠ cu·ªëi c·ªßa weights
        print(f"S·ªë weights (bao g·ªìm bias): {len(self.weights)}")
        
        # Print complexity summary
        complexity_summary = self.complexity_tracker.get_summary_stats()
        print(f"üìä Complexity Summary:")
        print(f"   Total operations: {complexity_summary['total_operations']:,}")
        print(f"   Function evaluations: {complexity_summary['function_evaluations']}")
        print(f"   Gradient evaluations: {complexity_summary['gradient_evaluations']}")
        
        # L·∫•y k·∫øt qu·∫£ t·ªët nh·∫•t thay v√¨ k·∫øt qu·∫£ cu·ªëi c√πng
        best_results = self._get_best_results()
        best_weights = best_results['best_weights']
        best_loss = best_results['best_loss']
        best_gradient_norm = best_results['best_gradient_norm']
        best_epoch = best_results['best_epoch']
        
        print(f"üèÜ Best results (gradient norm th·∫•p nh·∫•t):")
        print(f"   Best epoch: {best_epoch}")
        print(f"   Best loss: {best_loss:.6f}")
        print(f"   Best gradient norm: {best_gradient_norm:.6f}")
        
        return {
            'weights': best_weights,  # Tr·∫£ v·ªÅ best weights thay v√¨ final
            'bias': best_weights[-1],  # Bias ri√™ng ƒë·ªÉ t∆∞∆°ng th√≠ch
            'velocity': getattr(self, 'velocity', None),  # SGD-specific: Include velocity if using momentum
            'loss_history': self.loss_history,
            'gradient_norms': self.gradient_norms,
            'weights_history': self.weights_history,
            'step_sizes_history': self.learning_rates_history,  # Renamed for consistency with GD
            'learning_rates_history': self.learning_rates_history,  # Keep SGD-specific name too
            'training_time': self.training_time,
            'converged': self.converged,
            'final_iteration': self.final_epoch,  # Renamed for consistency with GD
            'final_epoch': self.final_epoch,  # Keep SGD-specific name too
            'best_iteration': best_epoch,  # Renamed for consistency with GD
            'best_epoch': best_epoch,  # Keep SGD-specific name too
            'best_loss': best_loss,
            'best_gradient_norm': best_gradient_norm,
            'final_loss': self.loss_history[-1],  # ƒê·ªÉ so s√°nh
            'final_gradient_norm': self.gradient_norms[-1],  # ƒê·ªÉ so s√°nh
            'complexity_metrics': self.complexity_tracker.get_complexity_analysis(self.final_epoch, self.converged) if hasattr(self, 'complexity_tracker') and self.complexity_tracker else None
        }

    def predict(self, X):
        """D·ª± ƒëo√°n v·ªõi d·ªØ li·ªáu X 
        
        Tr·∫£ v·ªÅ:
            predictions: D·ª± ƒëo√°n tr√™n log scale
            
        L∆∞u √Ω:
            - Model ƒë∆∞·ª£c train tr√™n log-transformed targets
            - D·ª± ƒëo√°n tr·∫£ v·ªÅ ·ªü log scale
            - Bias ƒë√£ ƒë∆∞·ª£c t√≠ch h·ª£p v√†o weights: y = Xw (v·ªõi X ƒë√£ c√≥ c·ªôt bias)
            - S·ª≠ d·ª•ng np.expm1() ƒë·ªÉ chuy·ªÉn v·ªÅ gi√° g·ªëc khi c·∫ßn
        """
        if self.weights is None:
            raise ValueError("Model ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. H√£y g·ªçi fit() tr∆∞·ªõc.")
        
        if X.shape[1] != len(self.weights) - 1:  # -1 for bias
            raise ValueError(f"S·ªë features kh√¥ng kh·ªõp: X c√≥ {X.shape[1]} features, model ƒë∆∞·ª£c train v·ªõi {len(self.weights) - 1} features")
        
        # Th√™m c·ªôt bias v√†o X cho prediction
        X_with_bias = add_bias_column(X)
        return du_doan(X_with_bias, self.weights, None)

    def evaluate(self, X_test, y_test):
        """ƒê√°nh gi√° model tr√™n test set"""
        if self.weights is None:
            raise ValueError("Model ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. H√£y g·ªçi fit() tr∆∞·ªõc.")
        
        if X_test.shape[1] != len(self.weights) - 1:  # -1 for bias
            raise ValueError(f"S·ªë features kh√¥ng kh·ªõp: X_test c√≥ {X_test.shape[1]} features, model ƒë∆∞·ª£c train v·ªõi {len(self.weights) - 1} features")
        
        if len(X_test) != len(y_test):
            raise ValueError(f"X_test v√† y_test ph·∫£i c√≥ c√πng s·ªë samples: {len(X_test)} vs {len(y_test)}")
        
        # S·ª≠ d·ª•ng bias t·ª´ weights (ph·∫ßn t·ª≠ cu·ªëi) ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi h√†m c≈©
        bias_value = self.weights[-1]
        weights_without_bias = self.weights[:-1]
        metrics = danh_gia_mo_hinh(weights_without_bias, X_test, y_test, bias_value)
        in_ket_qua_danh_gia(metrics, self.training_time, 
                           f"Stochastic Gradient Descent - {self.ham_loss.upper()}")
        return metrics

    def save_results(self, ten_file, base_dir="data/03_algorithms/stochastic_gd"):
        """
        L∆∞u k·∫øt qu·∫£ model v√†o file
        
        Parameters:
        - ten_file: T√™n file/folder ƒë·ªÉ l∆∞u k·∫øt qu·∫£
        - base_dir: Th∆∞ m·ª•c g·ªëc ƒë·ªÉ l∆∞u
        """
        if self.weights is None:
            raise ValueError("Model ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. H√£y g·ªçi fit() tr∆∞·ªõc.")
        
        # Setup results directory
        results_dir = Path(base_dir) / ten_file
        results_dir.mkdir(parents=True, exist_ok=True)
        
        # Get complexity analysis
        complexity_analysis = self.complexity_tracker.get_complexity_analysis(
            self.final_epoch, self.converged
        ) if hasattr(self, 'complexity_tracker') and self.complexity_tracker else None
        
        # L·∫•y k·∫øt qu·∫£ t·ªët nh·∫•t
        best_results = self._get_best_results()
        best_weights = best_results['best_weights']
        best_loss = best_results['best_loss']
        best_gradient_norm = best_results['best_gradient_norm'] 
        best_epoch = best_results['best_epoch']
        
        # Save comprehensive results.json
        results_data = {
            "algorithm": f"Stochastic Gradient Descent - {self.ham_loss.upper()}",
            "loss_function": self.ham_loss.upper(),
            "parameters": {
                "learning_rate": self.learning_rate,
                "max_epochs": self.so_epochs,
                "batch_size": self.batch_size,
                "tolerance": self.diem_dung,
                "learning_rate_schedule": self.learning_rate_schedule,
                "momentum": self.momentum,
                "random_state": self.random_state,
                "shuffle_each_epoch": self.shuffle_each_epoch,
                "randomize_each_epoch": self.randomize_each_epoch
            },
            "training_results": {
                "training_time": self.training_time,
                "converged": self.converged,
                "final_epoch": int(self.final_epoch),
                "total_epochs": int(self.so_epochs),
                "final_loss": float(self.loss_history[-1]),
                "final_gradient_norm": float(self.gradient_norms[-1]),
                # Th√™m th√¥ng tin best results
                "best_epoch": best_epoch,
                "best_loss": float(best_loss),
                "best_gradient_norm": float(best_gradient_norm),
                "improvement_from_final": {
                    "loss_improvement": float(self.loss_history[-1] - best_loss),
                    "gradient_improvement": float(self.gradient_norms[-1] - best_gradient_norm),
                    "epochs_earlier": int(self.final_epoch - best_epoch)
                }
            },
            "weights_analysis": {
                "n_features": int(len(best_weights) - 1),  # Kh√¥ng t√≠nh bias
                "n_weights_total": int(len(best_weights)),  # T√≠nh c·∫£ bias
                "bias_value": float(best_weights[-1]),
                "weights_without_bias": best_weights[:-1].tolist(),
                "complete_weight_vector": best_weights.tolist(),
                "weights_stats": {
                    "min": float(np.min(best_weights[:-1])),  # Stats ch·ªâ c·ªßa weights, kh√¥ng t√≠nh bias
                    "max": float(np.max(best_weights[:-1])),
                    "mean": float(np.mean(best_weights[:-1])),
                    "std": float(np.std(best_weights[:-1]))
                }
            },
            "convergence_analysis": {
                "epochs_to_converge": int(self.final_epoch),
                "best_epoch_found": best_epoch,
                "final_cost_change": float(self.loss_history[-1] - self.loss_history[-2]) if len(self.loss_history) > 1 else 0.0,
                "convergence_rate": "sublinear",  # SGD c√≥ convergence rate sublinear
                "loss_reduction_ratio": float(self.loss_history[0] / best_loss) if len(self.loss_history) > 0 else 1.0
            },
            "algorithm_specific": {
                "sgd_type": "mini_batch" if self.batch_size > 1 else "pure_sgd",
                "batch_size": self.batch_size,
                "learning_rate_schedule": self.learning_rate_schedule,
                "momentum_used": self.momentum > 0,
                "momentum_value": self.momentum if self.momentum > 0 else None,
                "shuffling_strategy": {
                    "shuffle_each_epoch": self.shuffle_each_epoch,
                    "randomize_each_epoch": self.randomize_each_epoch
                },
                "returns_best_result": True,  # ƒê√°nh d·∫•u r·∫±ng tr·∫£ v·ªÅ best result
                "stochastic_variance": True  # ƒê·∫∑c tr∆∞ng c·ªßa SGD
            }
        }
        
        # Add complexity metrics if available
        if complexity_analysis:
            results_data["computational_complexity"] = complexity_analysis
        
        if self.ham_loss in ['ridge', 'lasso']:
            results_data["parameters"]["regularization"] = self.regularization
        
        with open(results_dir / "results.json", 'w') as f:
            json.dump(results_data, f, indent=2)
        
        # Save training history
        training_df = pd.DataFrame({
            'epoch': range(0, len(self.loss_history)*self.convergence_check_freq, self.convergence_check_freq),
            'loss': self.loss_history,
            'gradient_norm': self.gradient_norms
        })
        
        # Save learning rates history for SGD
        if hasattr(self, 'learning_rates_history') and self.learning_rates_history:
            lr_df = pd.DataFrame({
                'epoch': range(len(self.learning_rates_history)),
                'learning_rate': self.learning_rates_history
            })
            lr_df.to_csv(results_dir / "learning_rates_history.csv", index=False)
            
        training_df.to_csv(results_dir / "training_history.csv", index=False)
        
        # Save complexity metrics separately for detailed analysis
        if complexity_analysis:
            with open(results_dir / "complexity_analysis.json", 'w') as f:
                json.dump(complexity_analysis, f, indent=2)
        
        print(f"\n‚úÖ K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: {results_dir.absolute()}")
        print(f"üèÜ S·ª≠ d·ª•ng best results t·ª´ epoch {best_epoch} (gradient norm: {best_gradient_norm:.6f})")
        if complexity_analysis:
            print(f"Complexity metrics saved to: complexity_analysis.json")
        
        return results_dir

    def plot_results(self, X_test, y_test, ten_file, base_dir="data/03_algorithms/stochastic_gd"):
        """
        T·∫°o c√°c bi·ªÉu ƒë·ªì visualization
        
        Parameters:
        - X_test, y_test: D·ªØ li·ªáu test ƒë·ªÉ v·∫Ω predictions
        - ten_file: T√™n file/folder ƒë·ªÉ l∆∞u bi·ªÉu ƒë·ªì
        - base_dir: Th∆∞ m·ª•c g·ªëc
        """
        if self.weights is None:
            raise ValueError("Model ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. H√£y g·ªçi fit() tr∆∞·ªõc.")
        
        results_dir = Path(base_dir) / ten_file
        results_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"\nüìä T·∫°o bi·ªÉu ƒë·ªì...")
        
        # 1. Convergence curves - now with actual epoch numbers
        print("   - V·∫Ω ƒë∆∞·ªùng h·ªôi t·ª•")
        # Create epoch values based on convergence_check_freq
        epochs = list(range(0, len(self.loss_history) * self.convergence_check_freq, self.convergence_check_freq))
        
        ve_duong_hoi_tu(self.loss_history, self.gradient_norms, 
                        iterations=epochs,
                        title=f"Stochastic Gradient Descent {self.ham_loss.upper()} - H·ªôi t·ª•",
                        save_path=str(results_dir / "convergence_analysis.png"))
        
        # 2. Predictions vs Actual
        print("   - So s√°nh d·ª± ƒëo√°n vs th·ª±c t·∫ø")
        y_pred_test = self.predict(X_test)
        ve_du_doan_vs_thuc_te(y_test, y_pred_test, 
                             title=f"Stochastic Gradient Descent {self.ham_loss.upper()} - D·ª± ƒëo√°n vs Th·ª±c t·∫ø",
                             save_path=str(results_dir / "predictions_vs_actual.png"))
        
        # 3. Optimization trajectory (ƒë∆∞·ªùng ƒë·ªìng m·ª©c)
        print("   - V·∫Ω ƒë∆∞·ªùng ƒë·ªìng m·ª©c optimization")
        
        # Chu·∫©n b·ªã X_test v·ªõi bias cho visualization
        X_test_with_bias = add_bias_column(X_test)
        
        # Create loss function compatible with visualization
        loss_func = lambda X, y, w: tinh_gia_tri_ham_loss(self.ham_loss, X, y, w, None, self.regularization)
        
        ve_duong_dong_muc_optimization(
            loss_function=loss_func,
            weights_history=self.weights_history,  # Pass full history
            X=X_test_with_bias, y=y_test,
            title=f"Stochastic Gradient Descent {self.ham_loss.upper()} - Optimization Path",
            save_path=str(results_dir / "optimization_trajectory.png"),
            original_iterations=self.final_epoch,  # Use actual number of epochs
            convergence_check_freq=self.convergence_check_freq,  # Pass convergence frequency
            max_trajectory_points=50  # Limit points for SGD (can be noisy)
        )
        
