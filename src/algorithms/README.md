# Thuáº­t ToÃ¡n Tá»‘i Æ¯u - Thá»­ Nghiá»‡m CÃ¡c Setup

Má»—i thuáº­t toÃ¡n Ä‘Æ°á»£c tá»• chá»©c trong folder riÃªng vá»›i nhiá»u setup khÃ¡c nhau Ä‘á»ƒ báº¡n thá»­ nghiá»‡m vÃ  so sÃ¡nh.

## ğŸ“ Cáº¥u TrÃºc ThÆ° Má»¥c

```
03_algorithms/
â”œâ”€â”€ gradient_descent/           # Gradient Descent vá»›i cÃ¡c setup
â”‚   â”œâ”€â”€ standard_setup.py      # Setup chuáº©n (lr=0.01)
â”‚   â”œâ”€â”€ fast_setup.py          # Setup nhanh (lr=0.1)
â”‚   â””â”€â”€ precise_setup.py       # Setup chÃ­nh xÃ¡c (lr=0.001)
â”œâ”€â”€ newton_method/             # Newton Method vá»›i cÃ¡c setup
â”œâ”€â”€ stochastic_gd/             # SGD vá»›i cÃ¡c setup
â”œâ”€â”€ ridge_regression/          # Ridge vá»›i cÃ¡c setup
â””â”€â”€ advanced_methods/          # CÃ¡c phÆ°Æ¡ng phÃ¡p nÃ¢ng cao
```

## ğŸš€ CÃ¡ch Sá»­ Dá»¥ng

### BÆ°á»›c 1: Äáº£m báº£o dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½
```bash
python src/02_preprocessing.py
```

### BÆ°á»›c 2: Chá»n thuáº­t toÃ¡n vÃ  setup muá»‘n thá»­
```bash
# Gradient Descent - Setup chuáº©n
python src/03_algorithms/gradient_descent/standard_setup.py

# Gradient Descent - Setup nhanh
python src/03_algorithms/gradient_descent/fast_setup.py

# Gradient Descent - Setup chÃ­nh xÃ¡c
python src/03_algorithms/gradient_descent/precise_setup.py
```

### BÆ°á»›c 3: Xem káº¿t quáº£
Má»—i setup sáº½ táº¡o folder riÃªng trong `data/03_algorithms/` vá»›i:
- Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ (JSON)
- Biá»ƒu Ä‘á»“ phÃ¢n tÃ­ch
- Lá»‹ch sá»­ training
- Weights Ä‘Ã£ há»c

## ğŸ“Š So SÃ¡nh CÃ¡c Setup

### Gradient Descent

| Setup | Learning Rate | Äáº·c Ä‘iá»ƒm | Khi nÃ o dÃ¹ng |
|-------|---------------|----------|--------------|
| **Standard** | 0.01 | á»”n Ä‘á»‹nh, an toÃ n | Há»c táº­p, sáº£n xuáº¥t |
| **Fast** | 0.1 | Nhanh, cÃ³ thá»ƒ dao Ä‘á»™ng | Thá»­ nghiá»‡m nhanh |
| **Precise** | 0.001 | Cháº­m, ráº¥t chÃ­nh xÃ¡c | NghiÃªn cá»©u, precision cao |

### CÃ¡ch Chá»n Setup

**ğŸ¯ Cho ngÆ°á»i má»›i há»c:**
- Báº¯t Ä‘áº§u vá»›i `standard_setup.py`
- Hiá»ƒu Ä‘Æ°á»£c cÃ¡ch hoáº¡t Ä‘á»™ng cÆ¡ báº£n
- Ãt rá»§i ro, káº¿t quáº£ á»•n Ä‘á»‹nh

**âš¡ Khi cáº§n káº¿t quáº£ nhanh:**
- DÃ¹ng `fast_setup.py`
- Cháº¥p nháº­n má»™t Ã­t trade-off vá» stability
- Tá»‘t cho prototyping

**ğŸ¯ Khi cáº§n precision tá»‘i Ä‘a:**
- DÃ¹ng `precise_setup.py`
- CÃ³ thá»i gian training lÃ¢u
- á»¨ng dá»¥ng production quan trá»ng

## ğŸ” PhÃ¢n TÃ­ch Káº¿t Quáº£

Má»—i setup sáº½ cho báº¡n:

### 1. Metrics CÆ¡ Báº£n
- **MSE**: Mean Squared Error (cÃ ng nhá» cÃ ng tá»‘t)
- **RÂ²**: R-squared (cÃ ng gáº§n 1 cÃ ng tá»‘t)
- **Training Time**: Thá»i gian training

### 2. PhÃ¢n TÃ­ch Chi Tiáº¿t
- **Convergence curves**: Xem thuáº­t toÃ¡n há»™i tá»¥ nhÆ° tháº¿ nÃ o
- **Gradient norms**: Theo dÃµi gradient giáº£m
- **Predictions vs Actual**: Xem Ä‘á»™ chÃ­nh xÃ¡c
- **Residuals**: PhÃ¢n tÃ­ch lá»—i

### 3. Äáº·c Äiá»ƒm Setup
- **Pros/Cons**: Æ¯u nhÆ°á»£c Ä‘iá»ƒm
- **Recommendations**: Khi nÃ o nÃªn dÃ¹ng
- **Stability analysis**: Äá»™ á»•n Ä‘á»‹nh

## ğŸ§ª Thá»­ Nghiá»‡m Tá»± Do

### Experiment Workflow
1. **Cháº¡y táº¥t cáº£ setup cá»§a 1 thuáº­t toÃ¡n**
2. **So sÃ¡nh metrics vÃ  visualization**
3. **Chá»n setup phÃ¹ há»£p vá»›i má»¥c tiÃªu**
4. **Ghi chÃº láº¡i insights**

### VÃ­ dá»¥ thá»­ nghiá»‡m:
```bash
# Thá»­ táº¥t cáº£ Gradient Descent setups
python src/03_algorithms/gradient_descent/standard_setup.py
python src/03_algorithms/gradient_descent/fast_setup.py
python src/03_algorithms/gradient_descent/precise_setup.py

# So sÃ¡nh káº¿t quáº£ trong data/03_algorithms/gradient_descent/
```

## ğŸ“ Ghi ChÃº Thá»­ Nghiá»‡m

Khi thá»­ nghiá»‡m, hÃ£y ghi chÃº:

### Quan sÃ¡t Quan Trá»ng
- Setup nÃ o cho káº¿t quáº£ tá»‘t nháº¥t?
- Trade-off giá»¯a speed vs accuracy?
- Stability cá»§a tá»«ng setup?
- PhÃ¹ há»£p vá»›i má»¥c tiÃªu cá»§a báº¡n?

### Template Ghi ChÃº
```
=== THá»¬ NGHIá»†M GRADIENT DESCENT ===
Date: [ngÃ y]
Dataset: [tÃªn dataset]

Results:
- Standard Setup: MSE = [x], Time = [y]s
- Fast Setup: MSE = [x], Time = [y]s  
- Precise Setup: MSE = [x], Time = [y]s

Best Setup: [tÃªn setup]
Reason: [lÃ½ do táº¡i sao tá»‘t nháº¥t]
Notes: [quan sÃ¡t khÃ¡c]
```

## ğŸ“ Há»c Há»i Tá»« Experiments

### Insights Quan Trá»ng
1. **Learning Rate Impact**: Xem áº£nh hÆ°á»Ÿng cá»§a LR
2. **Convergence Patterns**: Hiá»ƒu cÃ¡ch thuáº­t toÃ¡n há»™i tá»¥
3. **Speed vs Accuracy**: Trade-off quan trá»ng
4. **Stability**: Khi nÃ o setup á»•n Ä‘á»‹nh

### CÃ¢u Há»i ThÃº Vá»‹
- Setup nÃ o tá»‘t nháº¥t cho dataset nÃ y?
- Táº¡i sao fast setup láº¡i nhanh hÆ¡n?
- Khi nÃ o precise setup khÃ´ng cáº§n thiáº¿t?
- LÃ m tháº¿ nÃ o Ä‘á»ƒ tune parameters tá»‘t hÆ¡n?

## ğŸ”§ Customization

Báº¡n cÃ³ thá»ƒ modify parameters trong tá»«ng file:
- Thay Ä‘á»•i learning rate
- Äiá»u chá»‰nh max iterations  
- Thá»­ tolerance khÃ¡c
- ThÃªm analysis má»›i

VÃ­ dá»¥:
```python
# Trong standard_setup.py, thay Ä‘á»•i:
learning_rate = 0.05  # Thay vÃ¬ 0.01
max_iterations = 1500  # Thay vÃ¬ 1000
```

ChÃºc báº¡n thá»­ nghiá»‡m vui váº»! ğŸš€