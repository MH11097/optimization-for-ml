{
  "algorithm": "Subgradient Descent",
  "parameters": {
    "lambda_penalty": 0.1,
    "max_iterations": 750,
    "tolerance": 1e-08
  },
  "training_time": 22.159034252166748,
  "convergence": {
    "converged": false,
    "iterations": 711,
    "final_loss": 1.0937101149194046,
    "final_gradient_norm": 0.6833761322768429
  }
}