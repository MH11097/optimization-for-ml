{
  "algorithm": "Subgradient Descent",
  "parameters": {
    "lambda_penalty": 0.1,
    "max_iterations": 750,
    "tolerance": 1e-08
  },
  "training_time": 21.784179210662842,
  "convergence": {
    "converged": false,
    "iterations": 653,
    "final_loss": 1.097580311202145,
    "final_gradient_norm": 0.7152768767287875
  }
}