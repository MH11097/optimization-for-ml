#!/usr/bin/env python3
"""
SGDModel - Class cho Stochastic Gradient Descent
H·ªó tr·ª£ c√°c loss functions: MSE (Mean Squared Error)
"""

import pandas as pd
import numpy as np
from pathlib import Path
import time
import sys
import os
import json
import pickle

# Add the src directory to path ƒë·ªÉ import utils
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from utils.optimization_utils import (
    du_doan, danh_gia_mo_hinh, in_ket_qua_danh_gia, kiem_tra_dieu_kien_dung,
    tinh_gia_tri_ham_loss, tinh_gradient_ham_loss, tinh_hessian_ham_loss,
    add_bias_column
)
from utils.visualization_utils import (
    ve_duong_hoi_tu, ve_du_doan_vs_thuc_te, ve_duong_dong_muc_optimization
)


from utils.model_mixins import ComplexityTrackingMixin, OptimizationResultsMixin

class SGDModel(ComplexityTrackingMixin, OptimizationResultsMixin):
    """   
    Stochastic Gradient Descent v·ªõi h·ªó tr·ª£:
    - Multiple learning rate schedules
    - Batch processing v·ªõi size t√πy ch·ªçn
    - Momentum support
    - Enhanced shuffling strategies
    - Computational complexity tracking
    
    Parameters:
    - ham_loss: 'ols', 'ridge', 'lasso'  
    - learning_rate: T·ª∑ l·ªá h·ªçc ban ƒë·∫ßu
    - so_epochs: S·ªë epochs t·ªëi ƒëa
    - batch_size: K√≠ch th∆∞·ªõc batch
    - diem_dung: Ng∆∞·ª°ng h·ªôi t·ª•
    - learning_rate_schedule: Ph∆∞∆°ng ph√°p ƒëi·ªÅu ch·ªânh learning rate
    - momentum: H·ªá s·ªë momentum (0 = kh√¥ng d√πng momentum)
    - convergence_check_freq: T·∫ßn su·∫•t ki·ªÉm tra h·ªôi t·ª• (m·ªói N epochs)
    - shuffle_each_epoch: Enhanced shuffling v·ªõi seed m·ªõi m·ªói epoch
    - randomize_each_epoch: Full randomization v·ªõi replacement m·ªói epoch
    """
    
    def __init__(self, ham_loss='ols', learning_rate=0.01, so_epochs=100, batch_size=32, 
                 diem_dung=1e-5, regularization=0.01, learning_rate_schedule='constant',
                 momentum=0.0, convergence_check_freq=10, random_state=42,
                 # Enhanced shuffling strategies
                 shuffle_each_epoch=False, randomize_each_epoch=False,
                 # Learning rate schedule parameters
                 decay_rate=0.95, decay_steps=100):
        
        self.ham_loss = ham_loss.lower()
        self.learning_rate = learning_rate
        self.so_epochs = so_epochs
        self.batch_size = batch_size
        self.diem_dung = diem_dung
        self.regularization = regularization
        self.learning_rate_schedule = learning_rate_schedule
        self.momentum = momentum
        self.use_momentum = momentum > 0
        self.convergence_check_freq = convergence_check_freq
        self.random_state = random_state
        
        # Enhanced shuffling options
        self.shuffle_each_epoch = shuffle_each_epoch
        self.randomize_each_epoch = randomize_each_epoch
        
        # Learning rate schedule parameters
        self.decay_rate = decay_rate
        self.decay_steps = decay_steps
        
        # Initialize attributes to store results
        self.weights = None
        self.velocity = None  # For momentum
        self.loss_history = []
        self.gradient_norms = []
        self.weights_history = []
        self.learning_rates_history = []
        self.training_time = 0
        self.converged = False
        self.final_epoch = 0
        self.final_cost = 0
        
        print(f"üîß SGD Model initialized:")
        print(f"   Loss function: {self.ham_loss.upper()}")
        print(f"   Learning rate: {self.learning_rate} ({self.learning_rate_schedule})")
        print(f"   Epochs: {self.so_epochs}, Batch size: {self.batch_size}")
        print(f"   Momentum: {self.momentum}")
        print(f"   Random state: {self.random_state}")
        if regularization and ham_loss in ['ridge', 'lasso']:
            print(f"   Regularization: {self.regularization}")

    def _get_best_results(self):
        """
        L·∫•y k·∫øt qu·∫£ t·ªët nh·∫•t d·ª±a tr√™n gradient norm th·∫•p nh·∫•t
        
        Returns:
            dict: Ch·ª©a best_weights, best_loss, best_gradient_norm, best_epoch
        """
        if not self.gradient_norms:
            raise ValueError("Kh√¥ng c√≥ l·ªãch s·ª≠ gradient norms ƒë·ªÉ t√¨m k·∫øt qu·∫£ t·ªët nh·∫•t")
        
        # T√¨m index c√≥ gradient norm th·∫•p nh·∫•t
        best_idx = np.argmin(self.gradient_norms)
        
        return {
            'best_weights': self.weights_history[best_idx],
            'best_loss': self.loss_history[best_idx],
            'best_gradient_norm': self.gradient_norms[best_idx],
            'best_epoch': best_idx * self.convergence_check_freq
        }
    
    def _get_learning_rate(self, epoch):
        """
        T√≠nh learning rate theo schedule ƒë∆∞·ª£c ch·ªçn
        
        Args:
            epoch: Epoch hi·ªán t·∫°i (0-indexed)
        """
        if self.learning_rate_schedule == 'constant':
            return self.learning_rate
        elif self.learning_rate_schedule == 'linear_decay':
            # Gi·∫£m tuy·∫øn t√≠nh: lr * (1 - epoch/max_epochs)
            decay_factor = 1.0 - (epoch / max(self.so_epochs, 1))
            return self.learning_rate * max(decay_factor, 0.01)  # Minimum 1% of original
        elif self.learning_rate_schedule == 'exponential_decay':
            # Gi·∫£m exponential: lr * decay_rate^(epoch/decay_steps)
            return self.learning_rate * (self.decay_rate ** (epoch / self.decay_steps))
        elif self.learning_rate_schedule == 'sqrt_decay':
            # Gi·∫£m theo sqrt: lr / sqrt(epoch + 1)
            return self.learning_rate / np.sqrt(epoch + 1)
        elif self.learning_rate_schedule == 'backtracking':
            # Simple backtracking implementation for SGD (placeholder)
            return self.learning_rate * (0.9 ** (epoch // 10))
        else:
            return self.learning_rate
    
    def _tinh_gradient_sample(self, xi, yi, weights):
        """
        T√≠nh gradient cho 1 sample
        
        Args:
            xi: Feature vector for sample i (ƒë√£ c√≥ bias)
            yi: Target value for sample i  
            weights: Weight vector hi·ªán t·∫°i
        """
        # Prediction
        pred = np.dot(xi, weights)
        residual = pred - yi
        
        if self.ham_loss == 'ols':
            # MSE gradient: 2 * (pred - y) * x
            gradient = 2 * residual * xi
        elif self.ham_loss == 'ridge':
            # Ridge gradient: MSE + L2 regularization
            gradient = 2 * residual * xi + 2 * self.regularization * weights
            # Don't regularize bias (last element)
            gradient[-1] -= 2 * self.regularization * weights[-1]
        elif self.ham_loss == 'lasso':
            # Lasso gradient: MSE + L1 regularization (simplified)
            gradient = 2 * residual * xi + self.regularization * np.sign(weights)
            # Don't regularize bias
            gradient[-1] -= self.regularization * np.sign(weights[-1])
        else:
            raise ValueError(f"Unsupported loss function: {self.ham_loss}")
            
        return gradient
    
    def _tinh_chi_phi(self, X, y, weights):
        """
        T√≠nh chi ph√≠ (cost) cho to√†n b·ªô dataset
        
        Args:
            X: Feature matrix (ƒë√£ c√≥ bias)
            y: Target vector
            weights: Weight vector
        """
        predictions = X @ weights
        residuals = predictions - y
        
        if self.ham_loss == 'ols':
            cost = np.mean(residuals ** 2)
        elif self.ham_loss == 'ridge':
            mse_cost = np.mean(residuals ** 2)
            l2_penalty = self.regularization * np.sum(weights[:-1] ** 2)  # Kh√¥ng regularize bias
            cost = mse_cost + l2_penalty
        elif self.ham_loss == 'lasso':
            mse_cost = np.mean(residuals ** 2)
            l1_penalty = self.regularization * np.sum(np.abs(weights[:-1]))  # Kh√¥ng regularize bias
            cost = mse_cost + l1_penalty
        else:
            raise ValueError(f"Unsupported loss function: {self.ham_loss}")
            
        return cost
    
    def _check_sgd_convergence(self, gradient_norm, cost_change, iteration, epoch_cost, loss_history):
        """
        Ki·ªÉm tra ƒëi·ªÅu ki·ªán d·ª´ng cho SGD
        
        Returns:
            (should_stop, converged, reason)
        """
        # Gradient norm convergence
        if gradient_norm < self.diem_dung:
            return True, True, f"Gradient norm {gradient_norm:.2e} < tolerance {self.diem_dung:.2e}"
        
        # Cost change convergence (less strict for SGD due to noise)
        if abs(cost_change) < self.diem_dung * 10:  # 10x more lenient for SGD
            return True, True, f"Cost change {abs(cost_change):.2e} < tolerance {self.diem_dung * 10:.2e}"
        
        # Max iterations reached
        if iteration >= self.so_epochs - 1:
            return True, False, f"Reached maximum epochs {self.so_epochs}"
        
        # Check for divergence (cost increasing significantly)
        if len(loss_history) >= 5:
            recent_costs = loss_history[-5:]
            if recent_costs[-1] > recent_costs[0] * 2:  # Cost doubled in last 5 checks
                return True, False, "Cost is increasing significantly (possible divergence)"
        
        return False, False, "Continuing training"
    
    def fit(self, X, y):
        """
        Hu·∫•n luy·ªán model v·ªõi d·ªØ li·ªáu X, y
        
        Returns:
        - dict: K·∫øt qu·∫£ training bao g·ªìm weights, loss_history, etc.
        """
        print(f"üöÄ Training Stochastic Gradient Descent - {self.ham_loss.upper()}")
        print(f"   Learning rate schedule: {self.learning_rate_schedule} - Base learning rate: {self.learning_rate}")
        print(f"   Epochs: {self.so_epochs}, Batch size: {self.batch_size}")
        print(f"   Random state: {self.random_state}")
        
        if self.shuffle_each_epoch:
            print(f"   üîÄ Enhanced shuffling: New random seed each epoch")
        if self.randomize_each_epoch:
            print(f"   üé≤ Full randomization: Sample with replacement each epoch")
        
        if self.momentum > 0 or self.use_momentum:
            print(f"   Using momentum: {self.momentum}")
        
        # Initialize complexity tracking
        self.init_complexity_tracker(X, y)
        
        np.random.seed(self.random_state)
        
        # Th√™m c·ªôt bias v√†o X
        X_with_bias = add_bias_column(X)
        print(f"   Original features: {X.shape[1]}, With bias: {X_with_bias.shape[1]}")
        
        n_samples, n_features_with_bias = X_with_bias.shape
        self.weights = np.random.normal(0, 0.01, n_features_with_bias)
        
        # Track initial memory allocation
        self.track_memory_allocation(len(self.weights))
        
        # Initialize velocity for momentum
        if self.momentum > 0 or self.use_momentum:
            self.velocity = np.zeros(n_features_with_bias)
            self.track_memory_allocation(len(self.velocity))
        
        # Reset histories
        self.loss_history = []
        self.gradient_norms = []
        self.weights_history = []
        self.learning_rates_history = []
        
        # Add convergence tracking
        self.converged = False
        self.final_epoch = 0
        
        start_time = time.time()
        
        for epoch in range(self.so_epochs):
            # Get learning rate for this epoch
            current_lr = self._get_learning_rate(epoch)
            self.learning_rates_history.append(current_lr)
            
            # Enhanced shuffling/randomization logic
            if self.randomize_each_epoch:
                # Full randomization with replacement - different samples each epoch
                epoch_seed = self.random_state + epoch * 1000  # Different seed each epoch
                np.random.seed(epoch_seed)
                indices = np.random.choice(n_samples, size=n_samples, replace=True)
                X_shuffled = X_with_bias[indices]
                y_shuffled = y[indices]
            elif self.shuffle_each_epoch:
                # Enhanced shuffling - new permutation seed each epoch
                epoch_seed = self.random_state + epoch * 100  # Different seed each epoch
                np.random.seed(epoch_seed)
                indices = np.random.permutation(n_samples)
                X_shuffled = X_with_bias[indices]
                y_shuffled = y[indices]
            else:
                # Standard shuffling (existing behavior)
                indices = np.random.permutation(n_samples)
                X_shuffled = X_with_bias[indices]
                y_shuffled = y[indices]
            
            epoch_gradients = []
            
            # Process in batches
            for i in range(0, n_samples, self.batch_size):
                end_idx = min(i + self.batch_size, n_samples)
                X_batch = X_shuffled[i:end_idx]
                y_batch = y_shuffled[i:end_idx]
                
                # Track batch processing operations
                batch_size_actual = len(X_batch)
                
                # T√≠nh gradient cho batch
                batch_gradient = np.zeros(n_features_with_bias)
                
                for j in range(len(X_batch)):
                    xi = X_batch[j]
                    yi = y_batch[j]
                    sample_gradient = self._tinh_gradient_sample(xi, yi, self.weights)
                    batch_gradient += sample_gradient
                    
                    # Track gradient computation for each sample
                    self.track_gradient_evaluation((1, n_features_with_bias))
                    self.track_vector_operation(n_features_with_bias, "basic")
                
                # Average gradient over batch
                batch_gradient /= len(X_batch)
                epoch_gradients.append(batch_gradient)
                
                # Track averaging operation
                self.track_vector_operation(n_features_with_bias, "basic")
                
                # Update weights with momentum if enabled
                if self.momentum > 0 or self.use_momentum:
                    # Momentum update: v = Œ≤ * v + ‚àáL
                    self.velocity = self.momentum * self.velocity + batch_gradient
                    # Weight update: w = w - Œ± * v
                    self.weights -= current_lr * self.velocity
                    
                    # Track momentum operations
                    self.track_vector_operation(n_features_with_bias, "basic")  # momentum update
                    self.track_vector_operation(n_features_with_bias, "basic")  # weight update
                else:
                    # Standard SGD update: w = w - Œ± * ‚àáL
                    self.weights -= current_lr * batch_gradient
                    
                    # Track weight update
                    self.track_vector_operation(n_features_with_bias, "basic")
                
                # Track weight copy for history
                self.track_memory_allocation(len(self.weights))
            
            # Ch·ªâ t√≠nh cost v√† l∆∞u history khi c·∫ßn thi·∫øt  
            should_log = (
                (epoch + 1) % self.convergence_check_freq == 0 or
                epoch == self.so_epochs - 1 or
                (epoch + 1) % 20 == 0  # Progress logging
            )
            
            if should_log:
                # Ch·ªâ t√≠nh cost khi c·∫ßn (expensive operation)
                epoch_cost = self._tinh_chi_phi(X_with_bias, y, self.weights)
                epoch_gradient_avg = np.mean(epoch_gradients, axis=0)
                gradient_norm = np.linalg.norm(epoch_gradient_avg)
                
                # Track cost and norm computations
                self.track_function_evaluation(X_with_bias.shape)
                self.track_vector_operation(len(epoch_gradient_avg), "norm")
                
                # L∆∞u v√†o history
                self.loss_history.append(epoch_cost)
                self.gradient_norms.append(gradient_norm)
                self.weights_history.append(self.weights.copy())
            
            # Check convergence v·ªõi t·∫ßn su·∫•t ƒë·ªãnh s·∫µn ho·∫∑c ·ªü epoch cu·ªëi
            if (epoch + 1) % self.convergence_check_freq == 0 or epoch == self.so_epochs - 1:
                # ƒê·∫£m b·∫£o c√≥ gradient_norm v√† epoch_cost cho convergence check
                if not should_log:
                    epoch_cost = self._tinh_chi_phi(X_with_bias, y, self.weights)
                    epoch_gradient_avg = np.mean(epoch_gradients, axis=0)
                    gradient_norm = np.linalg.norm(epoch_gradient_avg)
                    
                    # Track additional computations
                    self.track_function_evaluation(X_with_bias.shape)
                    self.track_vector_operation(len(epoch_gradient_avg), "norm")
                    
                cost_change = 0.0 if len(self.loss_history) == 0 else (self.loss_history[-1] - epoch_cost) if len(self.loss_history) == 1 else (self.loss_history[-2] - self.loss_history[-1])
                
                # Use SGD-specific convergence check
                should_stop, converged, reason = self._check_sgd_convergence(
                    gradient_norm=gradient_norm,
                    cost_change=cost_change,
                    iteration=epoch,
                    epoch_cost=epoch_cost,
                    loss_history=self.loss_history
                )
                
                if should_stop:
                    if converged:
                        print(f"‚úÖ SGD converged: {reason}")
                        self.mark_convergence_tracking(epoch + 1)
                    else:
                        print(f"‚ö†Ô∏è SGD stopped (not converged): {reason}")
                    self.converged = converged
                    self.final_epoch = epoch + 1
                    break
            
            # Progress update - ch·ªâ print khi ƒë√£ c√≥ data
            if (epoch + 1) % 20 == 0 and should_log:
                print(f"   Epoch {epoch + 1}: Cost = {epoch_cost:.6f}, Gradient = {gradient_norm:.6f}, LR = {current_lr}")
            
            # End epoch tracking
            self.end_iteration_tracking()
        
        self.training_time = time.time() - start_time
        self.final_cost = self.loss_history[-1]
        
        if not self.converged:
            print(f"‚èπÔ∏è ƒê·∫°t t·ªëi ƒëa {self.so_epochs} epochs")
            self.final_epoch = self.so_epochs
            
        print(f"Th·ªùi gian training: {self.training_time:.2f}s")
        print(f"Loss cu·ªëi: {self.final_cost:.6f}")
        print(f"Bias cu·ªëi: {self.weights[-1]:.6f}")  # Bias l√† ph·∫ßn t·ª≠ cu·ªëi c·ªßa weights
        print(f"S·ªë weights (bao g·ªìm bias): {len(self.weights)}")
        
        # Print complexity summary
        self.print_complexity_summary()
        
        # L·∫•y k·∫øt qu·∫£ t·ªët nh·∫•t thay v√¨ k·∫øt qu·∫£ cu·ªëi c√πng
        best_results = self._get_best_results()
        best_weights = best_results['best_weights']
        best_loss = best_results['best_loss']
        best_gradient_norm = best_results['best_gradient_norm']
        best_epoch = best_results['best_epoch']
        
        print(f"üèÜ Best results (gradient norm th·∫•p nh·∫•t):")
        print(f"   Best epoch: {best_epoch}")
        print(f"   Best loss: {best_loss:.6f}")
        print(f"   Best gradient norm: {best_gradient_norm:.6f}")
        
        return {
            'weights': best_weights,  # Tr·∫£ v·ªÅ best weights thay v√¨ final
            'bias': best_weights[-1],  # Bias ri√™ng ƒë·ªÉ t∆∞∆°ng th√≠ch
            'velocity': getattr(self, 'velocity', None),  # Include velocity if using momentum
            'loss_history': self.loss_history,
            'gradient_norms': self.gradient_norms,
            'weights_history': self.weights_history,
            'learning_rates_history': self.learning_rates_history,
            'training_time': self.training_time,
            'final_cost': self.final_cost,
            'converged': self.converged,
            'final_epoch': self.final_epoch,
            'best_epoch': best_epoch,
            'best_loss': best_loss,
            'best_gradient_norm': best_gradient_norm,
            'final_loss': self.loss_history[-1],  # ƒê·ªÉ so s√°nh
            'final_gradient_norm': self.gradient_norms[-1],  # ƒê·ªÉ so s√°nh
            'complexity_metrics': self.get_complexity_analysis(self.final_epoch, self.converged)
        }
        
