#!/usr/bin/env python3
"""
GradientDescentModel - Class cho Gradient Descent Algorithm
H·ªó tr·ª£ c√°c loss functions: OLS, Ridge, Lasso
"""

import pandas as pd
import numpy as np
from pathlib import Path
import time
import sys
import os
import json

# Add the src directory to path ƒë·ªÉ import utils
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from utils.optimization_utils import (
    du_doan, danh_gia_mo_hinh, in_ket_qua_danh_gia, kiem_tra_hoi_tu,
    tinh_gia_tri_ham_loss, tinh_gradient_ham_loss, tinh_hessian_ham_loss,
    add_bias_column
)
from utils.visualization_utils import (
    ve_duong_hoi_tu, ve_duong_dong_muc_optimization, ve_du_doan_vs_thuc_te
)


class GradientDescentModel:
    """   
    Parameters:
    - ham_loss: 'ols', 'ridge', 'lasso'
    - learning_rate: T·ª∑ l·ªá h·ªçc
    - so_lan_thu: S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa
    - diem_dung: Ng∆∞·ª°ng h·ªôi t·ª•
    - regularization: Tham s·ªë regularization cho Ridge/Lasso
    - convergence_check_freq: T·∫ßn su·∫•t ki·ªÉm tra h·ªôi t·ª• (m·ªói N iterations)
    """
    
    def __init__(self, ham_loss='ols', learning_rate=0.1, so_lan_thu=10000, diem_dung=1e-5, regularization=0.01, 
                 convergence_check_freq=100, step_size_method='constant', backtrack_c1=1e-4, backtrack_rho=0.8, 
                 adaptive_beta1=0.9, adaptive_beta2=0.999, adaptive_eps=1e-8, wolfe_c2=0.9, decay_gamma=0.95):
        self.ham_loss = ham_loss.lower()
        self.learning_rate = learning_rate
        self.so_lan_thu = so_lan_thu
        self.diem_dung = diem_dung
        self.regularization = regularization
        self.convergence_check_freq = convergence_check_freq
        
        # Step size method parameters
        self.step_size_method = step_size_method  # 'constant', 'backtracking', 'decreasing_linear', 'decreasing_sqrt', 'adaptive'
        self.backtrack_c1 = backtrack_c1  # Armijo constant
        self.backtrack_rho = backtrack_rho  # Backtracking reduction factor
        self.adaptive_beta1 = adaptive_beta1  # Adam-like momentum parameter
        self.adaptive_beta2 = adaptive_beta2  # Adam-like second moment parameter
        self.adaptive_eps = adaptive_eps  # Adam-like epsilon
        self.wolfe_c2 = wolfe_c2  # Wolfe curvature condition parameter
        self.decay_gamma = decay_gamma  # Exponential decay factor
        
        # Adaptive step size variables
        if self.step_size_method == 'adaptive':
            self.m = None  # First moment estimate
            self.v = None  # Second moment estimate
            self.t = 0  # Time step
        
        # S·ª≠ d·ª•ng unified functions v·ªõi format m·ªõi (bias trong X)
        self.loss_func = lambda X, y, w: tinh_gia_tri_ham_loss(self.ham_loss, X, y, w, None, self.regularization)
        self.grad_func = lambda X, y, w: tinh_gradient_ham_loss(self.ham_loss, X, y, w, None, self.regularization)
        
        # Kh·ªüi t·∫°o c√°c thu·ªôc t√≠nh l∆∞u k·∫øt qu·∫£
        self.weights = None
        self.loss_history = []
        self.gradient_norms = []
        self.weights_history = []
        self.step_sizes_history = []  # L∆∞u step size cho m·ªói iteration
        self.training_time = 0
        self.converged = False
        self.final_iteration = 0
    
    def _backtracking_line_search(self, X, y, weights, gradient, direction):
        """
        Th·ª±c hi·ªán backtracking line search theo thu·∫≠t to√°n Armijo
        
        Args:
            X, y: D·ªØ li·ªáu
            weights: Tr·ªçng s·ªë hi·ªán t·∫°i
            gradient: Gradient t·∫°i weights hi·ªán t·∫°i
            direction: H∆∞·ªõng t√¨m ki·∫øm (th∆∞·ªùng l√† -gradient)
        
        Returns:
            alpha: Step size ph√π h·ª£p
        """
        alpha = self.learning_rate
        current_loss = self.loss_func(X, y, weights)
        
        # Armijo condition: f(x + alpha*d) <= f(x) + c1*alpha*grad^T*d
        armijo_lhs = lambda a: self.loss_func(X, y, weights + a * direction)
        armijo_rhs = lambda a: current_loss + self.backtrack_c1 * a * np.dot(gradient, direction)
        
        # Backtracking loop
        max_backtracks = 50
        for _ in range(max_backtracks):
            if armijo_lhs(alpha) <= armijo_rhs(alpha):
                break
            alpha *= self.backtrack_rho
        
        return alpha

    
    def _wolfe_line_search(self, X, y, weights, gradient, direction):
        """
        Th·ª±c hi·ªán Wolfe line search v·ªõi c·∫£ Armijo v√† curvature conditions
        
        Args:
            X, y: D·ªØ li·ªáu
            weights: Tr·ªçng s·ªë hi·ªán t·∫°i
            gradient: Gradient t·∫°i weights hi·ªán t·∫°i
            direction: H∆∞·ªõng t√¨m ki·∫øm (th∆∞·ªùng l√† -gradient)
        
        Returns:
            alpha: Step size ph√π h·ª£p
        """
        alpha = self.learning_rate
        current_loss = self.loss_func(X, y, weights)
        
        # Armijo condition: f(x + alpha*d) <= f(x) + c1*alpha*grad^T*d
        def armijo_condition(a):
            new_weights = weights + a * direction
            new_loss = self.loss_func(X, y, new_weights)
            return new_loss <= current_loss + self.backtrack_c1 * a * np.dot(gradient, direction)
        
        # Curvature condition (strong Wolfe): |grad(x + alpha*d)^T * d| <= c2 * |grad(x)^T * d|
        def curvature_condition(a):
            new_weights = weights + a * direction
            new_gradient, _ = self.grad_func(X, y, new_weights)  # Extract only gradient_w, ignore gradient_b
            return abs(np.dot(new_gradient, direction)) <= self.wolfe_c2 * abs(np.dot(gradient, direction))
        
        # Simple backtracking with both conditions
        max_backtracks = 50
        for _ in range(max_backtracks):
            if armijo_condition(alpha) and curvature_condition(alpha):
                break
            alpha *= self.backtrack_rho
            
            # Prevent alpha from becoming too small
            if alpha < 1e-10:
                alpha = 1e-10
                break
        
        return alpha
    
    def _get_step_size(self, iteration, gradient, X=None, y=None, weights=None):
        """
        T√≠nh step size theo method ƒë∆∞·ª£c ch·ªçn
        
        Args:
            iteration: Iteration hi·ªán t·∫°i (b·∫Øt ƒë·∫ßu t·ª´ 0)
            gradient: Gradient hi·ªán t·∫°i
            X, y, weights: C·∫ßn thi·∫øt cho backtracking
        
        Returns:
            step_size: Step size cho iteration n√†y
        """
        if self.step_size_method == 'constant':
            return self.learning_rate
        
        elif self.step_size_method == 'decreasing_linear':
            # Alpha / (iteration + 1)
            return self.learning_rate / (iteration + 1)
        
        elif self.step_size_method == 'decreasing_sqrt':
            # Alpha / sqrt(iteration + 1)
            return self.learning_rate / np.sqrt(iteration + 1)
        
        elif self.step_size_method == 'decreasing_exponential':
            # Alpha * gamma^iteration
            return self.learning_rate * (self.decay_gamma ** iteration)
        
        elif self.step_size_method == 'backtracking':
            # Line search v·ªõi Armijo condition
            direction = -gradient  # Steepest descent direction
            return self._backtracking_line_search(X, y, weights, gradient, direction)
        
        elif self.step_size_method == 'wolfe_conditions':
            # Wolfe line search v·ªõi both Armijo v√† curvature conditions
            direction = -gradient  # Steepest descent direction
            return self._wolfe_line_search(X, y, weights, gradient, direction)
        
        elif self.step_size_method == 'adaptive':
            # Adam-like adaptive learning rate
            self.t += 1
            
            # Initialize moments on first iteration
            if self.m is None:
                self.m = np.zeros_like(gradient)
                self.v = np.zeros_like(gradient)
            
            # Update biased first and second moments
            self.m = self.adaptive_beta1 * self.m + (1 - self.adaptive_beta1) * gradient
            self.v = self.adaptive_beta2 * self.v + (1 - self.adaptive_beta2) * (gradient ** 2)
            
            # Bias correction
            m_hat = self.m / (1 - self.adaptive_beta1 ** self.t)
            v_hat = self.v / (1 - self.adaptive_beta2 ** self.t)
            
            # Return adaptive step size scaled by base learning rate
            return self.learning_rate / (np.sqrt(v_hat) + self.adaptive_eps)
        
        else:
            raise ValueError(f"Unknown step_size_method: {self.step_size_method}")
        
    def fit(self, X, y):
        """
        Hu·∫•n luy·ªán model v·ªõi d·ªØ li·ªáu X, y
        
        Returns:
        - dict: K·∫øt qu·∫£ training bao g·ªìm weights, bias, loss_history, etc.
        """
        print(f"üöÄ Training Gradient Descent - {self.ham_loss.upper()} - ")
        print(f"   Step size method: {self.step_size_method} - Base learning rate: {self.learning_rate} - Max iterations: {self.so_lan_thu}")
        if self.ham_loss in ['ridge', 'lasso']:
            print(f"   Regularization: {self.regularization}")
        
        # Th√™m c·ªôt bias v√†o X
        X_with_bias = add_bias_column(X)
        print(f"   Num of features: {X.shape[1]} (+1)")
        
        # Initialize weights (bao g·ªìm bias ·ªü cu·ªëi)
        n_features_with_bias = X_with_bias.shape[1]
        self.weights = np.random.normal(0, 0.01, n_features_with_bias)
        
        # Reset histories
        self.loss_history = []
        self.gradient_norms = []
        self.weights_history = []
        self.step_sizes_history = []
        
        # Reset adaptive parameters if needed
        if self.step_size_method == 'adaptive':
            self.m = None
            self.v = None
            self.t = 0
        
        start_time = time.time()
        
        for lan_thu in range(self.so_lan_thu):
            # T√≠nh gradient (lu√¥n c·∫ßn cho weight update)
            gradient_w, _ = self.grad_func(X_with_bias, y, self.weights) 
            
            # T√≠nh step size cho iteration n√†y
            if self.step_size_method == 'adaptive':
                # For adaptive, step_size is a vector
                step_size = self._get_step_size(lan_thu, gradient_w, X_with_bias, y, self.weights)
                # Update weights with element-wise step size
                self.weights = self.weights - step_size * gradient_w
                # L∆∞u average step size cho visualization (ensure it's a scalar)
                avg_step_size = float(np.mean(step_size))
                self.step_sizes_history.append(avg_step_size)
            else:
                # For other methods, step_size is a scalar
                step_size = self._get_step_size(lan_thu, gradient_w, X_with_bias, y, self.weights)
                # Update weights with scalar step size
                self.weights = self.weights - step_size * gradient_w
                # Ensure step_size is a scalar before appending
                if np.isscalar(step_size):
                    self.step_sizes_history.append(float(step_size))
                else:
                    # If somehow we get a vector, take the mean
                    self.step_sizes_history.append(float(np.mean(step_size)))
            
            # Ch·ªâ t√≠nh loss v√† l∆∞u history khi c·∫ßn thi·∫øt
            should_check_converged = (
                (lan_thu + 1) % self.convergence_check_freq == 0 or 
                lan_thu == self.so_lan_thu - 1
            )
            
            if should_check_converged:
                # Ch·ªâ t√≠nh loss khi c·∫ßn (expensive operation)
                loss_value = self.loss_func(X_with_bias, y, self.weights)
                gradient_norm = np.linalg.norm(gradient_w)
                
                # L∆∞u v√†o history
                self.loss_history.append(loss_value)
                self.gradient_norms.append(gradient_norm)
                self.weights_history.append(self.weights.copy())                    
                cost_change = 0.0 if len(self.loss_history) == 0 else (self.loss_history[-1] - loss_value) if len(self.loss_history) == 1 else (self.loss_history[-2] - self.loss_history[-1])
                converged, reason = kiem_tra_hoi_tu(
                    gradient_norm=gradient_norm,
                    cost_change=cost_change,
                    iteration=lan_thu,
                    tolerance=self.diem_dung,
                    max_iterations=self.so_lan_thu,
                    loss_value=loss_value,
                    weights=self.weights
                )
                
                if converged:
                    print(f"‚úÖ Gradient Descent stopped: {reason}")
                    self.converged = True
                    self.final_iteration = lan_thu + 1
                    break

                # In th√™m step size
                current_step_size = self.step_sizes_history[-1] if self.step_sizes_history else 0
                print(f"   V√≤ng {lan_thu + 1}: Loss = {loss_value:.6f}, Gradient = {gradient_norm:.6f}, Step size = {current_step_size}")
        
        self.training_time = time.time() - start_time
        
        if not self.converged:
            print(f"‚úÖ Gradient Descent stopped: ƒê·∫°t t·ªëi ƒëa {self.so_lan_thu} v√≤ng l·∫∑p")
            self.final_iteration = self.so_lan_thu
        
        print(f"Th·ªùi gian training: {self.training_time:.2f}s")
        print(f"Loss cu·ªëi: {self.loss_history[-1]:.6f}")
        print(f"Gradient norm cu·ªëi: {self.gradient_norms[-1]:.6f}")  
        
        return {
            'weights': self.weights,  
            'bias': self.weights[-1], 
            'loss_history': self.loss_history,
            'gradient_norms': self.gradient_norms,
            'weights_history': self.weights_history,
            'step_sizes_history': self.step_sizes_history,
            'training_time': self.training_time,
            'converged': self.converged,
            'final_iteration': self.final_iteration
        }
    
    def predict(self, X):
        """D·ª± ƒëo√°n v·ªõi d·ªØ li·ªáu X 
        
        Tr·∫£ v·ªÅ:
            predictions: D·ª± ƒëo√°n tr√™n log scale
            
        L∆∞u √Ω:
            - Model ƒë∆∞·ª£c train tr√™n log-transformed targets
            - D·ª± ƒëo√°n tr·∫£ v·ªÅ ·ªü log scale
            - Bias ƒë√£ ƒë∆∞·ª£c t√≠ch h·ª£p v√†o weights: y = Xw (v·ªõi X ƒë√£ c√≥ c·ªôt bias)
            - S·ª≠ d·ª•ng np.expm1() ƒë·ªÉ chuy·ªÉn v·ªÅ gi√° g·ªëc khi c·∫ßn
        """
        if self.weights is None:
            raise ValueError("Model ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. H√£y g·ªçi fit() tr∆∞·ªõc.")
        
        # Th√™m c·ªôt bias v√†o X cho prediction
        X_with_bias = add_bias_column(X)
        return du_doan(X_with_bias, self.weights, None)
    
    def evaluate(self, X_test, y_test):
        """ƒê√°nh gi√° model tr√™n test set"""
        if self.weights is None:
            raise ValueError("Model ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. H√£y g·ªçi fit() tr∆∞·ªõc.")
        
        # S·ª≠ d·ª•ng bias t·ª´ weights (ph·∫ßn t·ª≠ cu·ªëi) ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi h√†m c≈©
        bias_value = self.weights[-1]
        weights_without_bias = self.weights[:-1]
        metrics = danh_gia_mo_hinh(weights_without_bias, X_test, y_test, bias_value)
        in_ket_qua_danh_gia(metrics, self.training_time, 
                           f"Gradient Descent - {self.ham_loss.upper()}")
        return metrics
    
    def save_results(self, ten_file, base_dir="data/03_algorithms/gradient_descent"):
        """
        L∆∞u k·∫øt qu·∫£ model v√†o file
        
        Parameters:
        - ten_file: T√™n file/folder ƒë·ªÉ l∆∞u k·∫øt qu·∫£
        - base_dir: Th∆∞ m·ª•c g·ªëc ƒë·ªÉ l∆∞u
        """
        if self.weights is None:
            raise ValueError("Model ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. H√£y g·ªçi fit() tr∆∞·ªõc.")
        
        # Setup results directory
        results_dir = Path(base_dir) / ten_file
        results_dir.mkdir(parents=True, exist_ok=True)
        
        # Save comprehensive results.json
        results_data = {
            "algorithm": f"Gradient Descent - {self.ham_loss.upper()}",
            "loss_function": self.ham_loss.upper(),
            "parameters": {
                "learning_rate": self.learning_rate,
                "max_iterations": self.so_lan_thu,
                "tolerance": self.diem_dung,
                "step_size_method": self.step_size_method
            },
            "training_results": {
                "training_time": self.training_time,
                "converged": self.converged,
                "final_iteration": self.final_iteration,
                "total_iterations": self.so_lan_thu,
                "final_loss": float(self.loss_history[-1]),
                "final_gradient_norm": float(self.gradient_norms[-1])
            },
            "weights_analysis": {
                "n_features": len(self.weights) - 1,  # Kh√¥ng t√≠nh bias
                "n_weights_total": len(self.weights),  # T√≠nh c·∫£ bias
                "bias_value": float(self.weights[-1]),
                "weights_without_bias": self.weights[:-1].tolist(),
                "complete_weight_vector": self.weights.tolist(),
                "weights_stats": {
                    "min": float(np.min(self.weights[:-1])),  # Stats ch·ªâ c·ªßa weights, kh√¥ng t√≠nh bias
                    "max": float(np.max(self.weights[:-1])),
                    "mean": float(np.mean(self.weights[:-1])),
                    "std": float(np.std(self.weights[:-1]))
                }
            },
            "convergence_analysis": {
                "iterations_to_converge": self.final_iteration,
                "final_cost_change": float(self.loss_history[-1] - self.loss_history[-2]) if len(self.loss_history) > 1 else 0.0,
                "convergence_rate": "linear",  # Gradient Descent c√≥ convergence rate tuy·∫øn t√≠nh
                "loss_reduction_ratio": float(self.loss_history[0] / self.loss_history[-1]) if len(self.loss_history) > 0 else 1.0
            },
            "algorithm_specific": {
                "gradient_descent_type": "standard",
                "step_size_method": self.step_size_method,
                "step_size_constant": self.step_size_method == 'constant',
                "momentum_used": False,
                "backtracking_parameters": {
                    "c1": self.backtrack_c1,
                    "rho": self.backtrack_rho
                } if self.step_size_method == 'backtracking' else None,
                "adaptive_parameters": {
                    "beta1": self.adaptive_beta1,
                    "beta2": self.adaptive_beta2,
                    "eps": self.adaptive_eps
                } if self.step_size_method == 'adaptive' else None
            }
        }
        
        if self.ham_loss in ['ridge', 'lasso']:
            results_data["parameters"]["regularization"] = self.regularization
        
        with open(results_dir / "results.json", 'w') as f:
            json.dump(results_data, f, indent=2)
        
        # Save training history
        training_df = pd.DataFrame({
            'iteration': range(0, len(self.loss_history)*self.convergence_check_freq, self.convergence_check_freq),
            'loss': self.loss_history,
            'gradient_norm': self.gradient_norms
        })
        
        # Save step sizes history separately if available
        if self.step_sizes_history:
            step_sizes_df = pd.DataFrame({
                'iteration': range(len(self.step_sizes_history)),
                'step_size': self.step_sizes_history
            })
            step_sizes_df.to_csv(results_dir / "step_sizes_history.csv", index=False)
        training_df.to_csv(results_dir / "training_history.csv", index=False)
        
        print(f"\n K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: {results_dir.absolute()}")
        return results_dir
    
    def plot_results(self, X_test, y_test, ten_file, base_dir="data/03_algorithms/gradient_descent"):
        """
        T·∫°o c√°c bi·ªÉu ƒë·ªì visualization
        
        Parameters:
        - X_test, y_test: D·ªØ li·ªáu test ƒë·ªÉ v·∫Ω predictions
        - ten_file: T√™n file/folder ƒë·ªÉ l∆∞u bi·ªÉu ƒë·ªì
        - base_dir: Th∆∞ m·ª•c g·ªëc
        """
        if self.weights is None:
            raise ValueError("Model ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. H√£y g·ªçi fit() tr∆∞·ªõc.")
        
        results_dir = Path(base_dir) / ten_file
        results_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"\nüìä T·∫°o bi·ªÉu ƒë·ªì...")
        
        # 1. Convergence curves
        print("   - V·∫Ω ƒë∆∞·ªùng h·ªôi t·ª•")
        ve_duong_hoi_tu(self.loss_history, self.gradient_norms, 
                        title=f"Gradient Descent {self.ham_loss.upper()} - H·ªôi t·ª•",
                        save_path=str(results_dir / "convergence_analysis.png"))
        
        # 2. Predictions vs Actual
        print("   - So s√°nh d·ª± ƒëo√°n vs th·ª±c t·∫ø")
        y_pred_test = self.predict(X_test)
        ve_du_doan_vs_thuc_te(y_test, y_pred_test, 
                             title=f"Gradient Descent {self.ham_loss.upper()} - D·ª± ƒëo√°n vs Th·ª±c t·∫ø",
                             save_path=str(results_dir / "predictions_vs_actual.png"))
        
        # 3. Optimization trajectory (ƒë∆∞·ªùng ƒë·ªìng m·ª©c)
        print("   - V·∫Ω ƒë∆∞·ªùng ƒë·ªìng m·ª©c optimization")
        
        # Chu·∫©n b·ªã X_test v·ªõi bias cho visualization
        X_test_with_bias = add_bias_column(X_test)
        
        ve_duong_dong_muc_optimization(
            loss_function=self.loss_func,
            weights_history=self.weights_history,  # Pass full history
            X=X_test_with_bias, y=y_test,
            title=f"Gradient Descent {self.ham_loss.upper()} - Optimization Path",
            save_path=str(results_dir / "optimization_trajectory.png"),
            original_iterations=self.final_iteration,  # Use actual number of iterations
            convergence_check_freq=self.convergence_check_freq,  # Pass convergence frequency
            max_trajectory_points=None  # None = show all points
        )
        
